# app/services/migracion.py (Versi√≥n Maestra v7.0 - Modo Fusi√≥n Segura / Sin Borrado Masivo)

from sqlalchemy.orm import Session
from sqlalchemy import func, delete, select, or_, and_, case, literal
from datetime import datetime, date
from decimal import Decimal
from fastapi import HTTPException
import traceback
import json
import os
import hmac
import hashlib
from app.core.config import settings

# Modelos
from ..models import (
    Empresa, Tercero, PlanCuenta, CentroCosto, TipoDocumento, Usuario,
    CupoAdicional, UsuarioFavorito, ConceptoFavorito,
    Bodega, GrupoInventario, TasaImpuesto, Producto, StockBodega, MovimientoInventario,
    Documento, MovimientoContable, FormatoImpresion,
    PlantillaMaestra, PlantillaDetalle, ListaPrecio, ReglaPrecioGrupo,
    CaracteristicaDefinicion, CaracteristicaValorProducto,
    DocumentoEliminado, MovimientoEliminado, AplicacionPago,
    LogOperacion
)
from ..schemas import migracion as schemas_migracion
from ..services import cartera as services_cartera

# --- NUEVOS MODELOS SOPORTADOS (v7.5) ---
from ..models.propiedad_horizontal import PHConfiguracion, PHConcepto, PHTorre, PHUnidad, PHVehiculo, PHMascota
from ..models.activo_fijo import ActivoFijo
from ..models.activo_categoria import ActivoCategoria

# --- NUEVOS MODELOS SOPORTADOS (v7.6) ---
from ..models.cotizacion import Cotizacion, CotizacionDetalle
from ..models.produccion import Receta, RecetaDetalle, RecetaRecurso, OrdenProduccion, OrdenProduccionInsumo, OrdenProduccionRecurso
from ..models.configuracion_produccion import ConfiguracionProduccion
from ..models.conciliacion_bancaria import (
    ImportConfig, ImportSession, BankMovement, Reconciliation, 
    ReconciliationMovement, AccountingConfig, ReconciliationAudit
)
# --- NUEVOS MODELOS SOPORTADOS (v7.7 - N√ìMINA) ---
from ..models.nomina import ConfiguracionNomina, TipoNomina, Empleado, Nomina, DetalleNomina

# =====================================================================================
# REGISTRO DECLARATIVO DE M√ìDULOS (v7.6)
# =====================================================================================
"""
Sistema declarativo para registrar nuevos m√≥dulos de migraci√≥n.
...
"""
MODULOS_ESPECIALIZADOS_CONFIG = {
    'cotizaciones': {
        'modelos_principales': [Cotizacion],
        'modelos_detalle': [CotizacionDetalle],
        'clave_natural': 'numero',
        'dependencias': ['terceros', 'productos', 'bodegas', 'usuarios'],
        'seccion_backup': 'cotizaciones',
        'descripcion': 'Cotizaciones maestras y sus detalles'
    },
    'produccion': {
        'modelos_principales': [Receta, OrdenProduccion, ConfiguracionProduccion],
        'modelos_detalle': [RecetaDetalle, RecetaRecurso, OrdenProduccionInsumo, OrdenProduccionRecurso],
        'clave_natural': 'nombre',  # Para recetas
        'dependencias': ['productos', 'tipos_documento', 'plan_cuentas', 'bodegas'],
        'seccion_backup': 'produccion',
        'descripcion': 'Recetas, √≥rdenes de producci√≥n, recursos e insumos'
    },
    'conciliacion_bancaria': {
        'modelos_principales': [ImportConfig, ImportSession, AccountingConfig],
        'modelos_detalle': [BankMovement, Reconciliation, ReconciliationMovement, ReconciliationAudit],
        'clave_natural': 'name',  # Para configuraciones
        'dependencias': ['terceros', 'plan_cuentas', 'centros_costo', 'usuarios'],
        'seccion_backup': 'conciliacion_bancaria',
        'descripcion': 'Configuraciones, sesiones, movimientos y conciliaciones bancarias'
    },
    'nomina': {
        'modelos_principales': [ConfiguracionNomina, TipoNomina, Empleado, Nomina],
        'modelos_detalle': [DetalleNomina],
        'clave_natural': 'numero_documento', # Para empleados
        'dependencias': ['terceros', 'plan_cuentas', 'tipos_documento'],
        'seccion_backup': 'nomina',
        'descripcion': 'Configuraci√≥n, empleados, tipos y documentos de n√≥mina'
    }
}

def validar_dependencias_modulo(db: Session, modulo_config: dict, empresa_id: int) -> dict:
    """Valida que existan las dependencias necesarias para un m√≥dulo."""
    dependencias_faltantes = []
    
    for dep in modulo_config.get('dependencias', []):
        if dep == 'terceros':
            count = db.query(func.count(Tercero.id)).filter(Tercero.empresa_id == empresa_id).scalar()
        elif dep == 'productos':
            count = db.query(func.count(Producto.id)).filter(Producto.empresa_id == empresa_id).scalar()
        elif dep == 'plan_cuentas':
            count = db.query(func.count(PlanCuenta.id)).filter(PlanCuenta.empresa_id == empresa_id).scalar()
        elif dep == 'tipos_documento':
            count = db.query(func.count(TipoDocumento.id)).filter(TipoDocumento.empresa_id == empresa_id).scalar()
        elif dep == 'bodegas':
            count = db.query(func.count(Bodega.id)).filter(Bodega.empresa_id == empresa_id).scalar()
        elif dep == 'centros_costo':
            count = db.query(func.count(CentroCosto.id)).filter(CentroCosto.empresa_id == empresa_id).scalar()
        elif dep == 'usuarios':
            count = db.query(func.count(Usuario.id)).join(Empresa).filter(Empresa.id == empresa_id).scalar()
        else:
            count = 0
            
        if count == 0:
            dependencias_faltantes.append(dep)
    
    return {
        'valido': len(dependencias_faltantes) == 0,
        'dependencias_faltantes': dependencias_faltantes
    }


# =====================================================================================
# 0. UTILIDAD DE SERIALIZACI√ìN
# =====================================================================================
class AlchemyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        if isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)

def serialize_model(model_dict):
    """Convierte tipos complejos a nativos de Python para JSON."""
    new_dict = {}
    for k, v in model_dict.items():
        if k == '_sa_instance_state': continue
        if isinstance(v, (datetime, date)):
            new_dict[k] = v.isoformat()
        elif isinstance(v, Decimal):
            new_dict[k] = float(v)
        else:
            new_dict[k] = v
    return new_dict

# =====================================================================================
# 1. MOTOR DE EXPORTACI√ìN (BACKUP)
# =====================================================================================

def compute_signature(data: dict) -> str:
    """Calcula la firma HMAC-SHA256 de un diccionario de datos."""
    # Ordenamos las llaves para asegurar consistencia en la serializaci√≥n
    json_str = json.dumps(data, sort_keys=True, separators=(',', ':'))
    signature = hmac.new(
        settings.SECRET_KEY.encode('utf-8'),
        json_str.encode('utf-8'),
        hashlib.sha256
    ).hexdigest()
    return signature

def generar_backup_json(db: Session, empresa_id: int, filtros: dict = None):
    """Genera el snapshot completo (JSON) de la empresa, FIRMADO DIGITALMENTE."""
    
    print(f"üîç [EXPORT] Iniciando exportaci√≥n para Empresa {empresa_id}")
    # print(f"üîç [EXPORT] Filtros Recibidos: {filtros}") # Debug

    # --- CORRECCI√ìN: Manejo de Snapshot de Seguridad (filtros=None) ---
    # Si no se reciben filtros (caso Safety Snapshot), asumimos EXPORTAR TODO.
    if filtros is None:
        filtros = {
            'paquetes': {
                'maestros': {
                    'plan_cuentas': True, 'terceros': True, 'centros_costo': True, 
                    'tipos_documento': True, 'bodegas': True, 'grupos_inventario': True, 
                    'tasas_impuesto': True, 'productos': True
                },
                'modulos_especializados': {
                    'propiedad_horizontal': True, 'activos_fijos': True, 'favoritos': True
                },
                'configuraciones': {
                    'plantillas_documentos': True, 'libreria_conceptos': True
                },
                'transacciones': True
            }
        }

    # Extract flags for easier access
    paquetes = filtros.get('paquetes', {})
    maestros_flags = paquetes.get('maestros', {})
    special_flags = paquetes.get('modulos_especializados', {}) 
    config_flags = paquetes.get('configuraciones', {})
    
    # Nuevos flags separados de transacciones
    transacciones_conta_flag = paquetes.get('transacciones_contabilidad', False)
    transacciones_inv_flag = paquetes.get('transacciones_inventario', False)
    
    # Retrocompatibilidad o flag "todo"
    transacciones_legacy_flag = paquetes.get('transacciones', False)
    if transacciones_legacy_flag:
        transacciones_conta_flag = True
        transacciones_inv_flag = True

    backup_data = {
        "metadata": {
            "fecha_generacion": datetime.utcnow().isoformat(),
            "version_sistema": "7.7",  # Actualizado v7.7 (N√≥mina + Flexibilidad)
            "empresa_id_origen": empresa_id
        },
        "empresa": {}, "configuracion": {}, "maestros": {}, "inventario": {}, 
        "propiedad_horizontal": {}, "activos_fijos": {}, "modulos_especializados": {}, 
        "cotizaciones": {}, "produccion": {}, "conciliacion_bancaria": {}, "nomina": {}, # <--- NUEVA SECCION
        "transacciones": []
    }

    # A. EMPRESA
    empresa = db.query(Empresa).filter(Empresa.id == empresa_id).first()
    if empresa:
        backup_data["empresa"] = serialize_model(empresa.__dict__)

    # B. CONFIGURACI√ìN (Formatos)
    if config_flags.get('plantillas_documentos', False):
        formatos = db.query(FormatoImpresion).filter(FormatoImpresion.empresa_id == empresa_id).all()
        backup_data["configuracion"]["formatos_impresion"] = [serialize_model(f.__dict__) for f in formatos]

    if config_flags.get('libreria_conceptos', False):
         pass # Futura implementaci√≥n

    # C. MAESTROS
    if maestros_flags.get('plan_cuentas', False):
        cuentas = db.query(PlanCuenta).filter(PlanCuenta.empresa_id == empresa_id).all()
        backup_data["maestros"]["plan_cuentas"] = [serialize_model(c.__dict__) for c in cuentas]

    if maestros_flags.get('terceros', False):
        terceros = db.query(Tercero).filter(Tercero.empresa_id == empresa_id).all()
        backup_data["maestros"]["terceros"] = [serialize_model(t.__dict__) for t in terceros]

    if maestros_flags.get('centros_costo', False):
        centros = db.query(CentroCosto).filter(CentroCosto.empresa_id == empresa_id).all()
        backup_data["maestros"]["centros_costo"] = [serialize_model(c.__dict__) for c in centros]

    if maestros_flags.get('tipos_documento', False):
        tipos = db.query(TipoDocumento).filter(TipoDocumento.empresa_id == empresa_id).all()
        backup_data["maestros"]["tipos_documento"] = [serialize_model(t.__dict__) for t in tipos]

    # D. INVENTARIO (Maestros)
    # D. INVENTARIO (Maestros)
    # --- AUTO-INCLUSI√ìN: Si se piden productos o grupos, se deben incluir listas de precio para evitar errores de FK ---
    should_export_listas = maestros_flags.get('listas_precio', False) or maestros_flags.get('productos', False) or maestros_flags.get('grupos_inventario', False)
    
    if should_export_listas:
        listas = db.query(ListaPrecio).filter(ListaPrecio.empresa_id == empresa_id).all()
        backup_data["inventario"]["listas_precio"] = [serialize_model(l.__dict__) for l in listas]

    if maestros_flags.get('bodegas', False):
        bodegas = db.query(Bodega).filter(Bodega.empresa_id == empresa_id).all()
        backup_data["inventario"]["bodegas"] = [serialize_model(b.__dict__) for b in bodegas]

    if maestros_flags.get('grupos_inventario', False):
        grupos = db.query(GrupoInventario).filter(GrupoInventario.empresa_id == empresa_id).all()
        grupos_list = []
        for g in grupos:
            g_dict = serialize_model(g.__dict__)
            if g.impuesto_predeterminado_id:
                imp = db.query(TasaImpuesto).filter(TasaImpuesto.id == g.impuesto_predeterminado_id).first()
                if imp: g_dict['impuesto_predeterminado_nombre'] = imp.nombre
            
            # --- EXPORTAR REGLAS DE PRECIO (Vinculadas a Listas) ---
            reglas = db.query(ReglaPrecioGrupo).filter(ReglaPrecioGrupo.grupo_inventario_id == g.id).all()
            reglas_list = []
            for r in reglas:
                r_dict = serialize_model(r.__dict__)
                # Enriquecer con nombre de lista para restauraci√≥n
                if r.lista_precio_id:
                    lp = db.query(ListaPrecio).filter(ListaPrecio.id == r.lista_precio_id).first()
                    if lp: r_dict['lista_nombre'] = lp.nombre
                reglas_list.append(r_dict)
            g_dict['reglas'] = reglas_list
                
            grupos_list.append(g_dict)
        backup_data["inventario"]["grupos"] = grupos_list

    if maestros_flags.get('tasas_impuesto', False):
        tasas = db.query(TasaImpuesto).filter(TasaImpuesto.empresa_id == empresa_id).all()
        backup_data["inventario"]["tasas_impuesto"] = [serialize_model(t.__dict__) for t in tasas]

    if maestros_flags.get('productos', False):
        productos = db.query(Producto).filter(Producto.empresa_id == empresa_id).all()
        backup_data["inventario"]["productos"] = [serialize_model(p.__dict__) for p in productos]

    # E. M√ìDULOS ESPECIALIZADOS
    if special_flags.get('propiedad_horizontal', False):
        # ... l√≥gica simplificada para PH ...
        ph_config = db.query(PHConfiguracion).filter(PHConfiguracion.empresa_id == empresa_id).all()
        backup_data["propiedad_horizontal"]["configuraciones"] = [serialize_model(c.__dict__) for c in ph_config]
        
    if special_flags.get('activos_fijos', False):
        # 1. Categor√≠as
        categorias = db.query(ActivoCategoria).filter(ActivoCategoria.empresa_id == empresa_id).all()
        backup_data["activos_fijos"]["categorias"] = [serialize_model(c.__dict__) for c in categorias]

        # 2. Activos
        activos = db.query(ActivoFijo).filter(ActivoFijo.empresa_id == empresa_id).all()
        # Enriquecer con nombre de categor√≠a para facilitaci√≥n de mapeo si falla ID
        activos_list = []
        for a in activos:
            a_dict = serialize_model(a.__dict__)
            if a.categoria_id:
                cat = db.query(ActivoCategoria).filter(ActivoCategoria.id == a.categoria_id).first()
                if cat: a_dict['categoria_nombre'] = cat.nombre
            activos_list.append(a_dict)
        backup_data["activos_fijos"]["activos"] = activos_list

    if special_flags.get('favoritos', False):
        favoritos = db.query(UsuarioFavorito).join(Usuario).join(Empresa).filter(Empresa.id == empresa_id).all()
        backup_data["modulos_especializados"]["favoritos"] = [serialize_model(f.__dict__) for f in favoritos]

    if special_flags.get('cotizaciones', False):
        cotizaciones = db.query(Cotizacion).filter(Cotizacion.empresa_id == empresa_id).all()
        cot_list = []
        for cot in cotizaciones:
            c_dict = serialize_model(cot.__dict__)
            c_dict['detalles'] = [serialize_model(d.__dict__) for d in cot.detalles]
            cot_list.append(c_dict)
        backup_data["cotizaciones"]["lista"] = cot_list
    
    if special_flags.get('produccion', False):
        # Implementar exportaci√≥n b√°sica de producci√≥n
        pass
        
    if special_flags.get('conciliacion_bancaria', False):
        # Implementar exportaci√≥n b√°sica de conciliaci√≥n
        pass

    # K. N√ìMINA (v7.7)
    if special_flags.get('nomina', False):
        # 1. Configuraci√≥n
        nom_configs = db.query(ConfiguracionNomina).filter(ConfiguracionNomina.empresa_id == empresa_id).all()
        backup_data["nomina"]["configuraciones"] = []
        for nc in nom_configs:
            nc_dict = serialize_model(nc.__dict__)
            # Mapeo de cuentas
            for k_cta in ['cuenta_sueldo_id', 'cuenta_auxilio_transporte_id', 'cuenta_horas_extras_id', 
                          'cuenta_comisiones_id', 'cuenta_otros_devengados_id', 'cuenta_salarios_por_pagar_id',
                          'cuenta_aporte_salud_id', 'cuenta_aporte_pension_id', 'cuenta_fondo_solidaridad_id',
                          'cuenta_retencion_fuente_id', 'cuenta_otras_deducciones_id']:
                val_id = getattr(nc, k_cta)
                if val_id:
                     cta = db.query(PlanCuenta).filter(PlanCuenta.id == val_id).first()
                     nc_dict[k_cta.replace('_id', '_codigo')] = cta.codigo if cta else None
            
            # Mapeo tipo doc
            if nc.tipo_documento_id:
                td = db.query(TipoDocumento).filter(TipoDocumento.id == nc.tipo_documento_id).first()
                nc_dict['tipo_documento_codigo'] = td.codigo if td else None

            backup_data["nomina"]["configuraciones"].append(nc_dict)

        # 2. Tipos de N√≥mina
        tipos_nom = db.query(TipoNomina).filter(TipoNomina.empresa_id == empresa_id).all()
        backup_data["nomina"]["tipos"] = [serialize_model(tn.__dict__) for tn in tipos_nom]

        # 3. Empleados
        empleados = db.query(Empleado).filter(Empleado.empresa_id == empresa_id).all()
        backup_data["nomina"]["empleados"] = []
        for emp in empleados:
            e_dict = serialize_model(emp.__dict__)
            if emp.tercero_id:
                tercero = db.query(Tercero).filter(Tercero.id == emp.tercero_id).first()
                e_dict['tercero_nit'] = tercero.nit if tercero else None
            if emp.tipo_nomina_id:
                tn = db.query(TipoNomina).filter(TipoNomina.id == emp.tipo_nomina_id).first()
                e_dict['tipo_nomina_nombre'] = tn.nombre if tn else None
            backup_data["nomina"]["empleados"].append(e_dict)

        # 4. Documentos de N√≥mina (Hist√≥rico)
        nominas = db.query(Nomina).filter(Nomina.empresa_id == empresa_id).all()
        backup_data["nomina"]["documentos"] = []
        for nom in nominas:
            n_dict = serialize_model(nom.__dict__)
            
            # Detalles
            detalles = []
            for det in nom.detalles:
                d_dict = serialize_model(det.__dict__)
                d_dict['empleado_documento'] = det.empleado.numero_documento if det.empleado else None
                if det.documento_contable_id:
                    doc = db.query(Documento).filter(Documento.id == det.documento_contable_id).first()
                    d_dict['documento_contable_numero'] = doc.numero if doc else None
                    d_dict['documento_contable_tipo'] = doc.tipo_documento.codigo if doc and doc.tipo_documento else None
                detalles.append(d_dict)
            
            n_dict['detalles'] = detalles
            backup_data["nomina"]["documentos"].append(n_dict)


    # F. TRANSACCIONES (MODIFICADO: Separaci√≥n Contabilidad / Inventario)
    # Se exportan documentos SI se pide contabilidad O inventario.
    # Dentro de cada documento, se incluyen las listas correspondientes seg√∫n los flags.
    if transacciones_conta_flag or transacciones_inv_flag:
        query_docs = db.query(Documento).filter(Documento.empresa_id == empresa_id)

        # --- APLICACI√ìN DE FILTROS ---
        if filtros:
            f_tercero = filtros.get('terceroId')
            if f_tercero:
                query_docs = query_docs.filter(Documento.beneficiario_id == f_tercero)
            
            f_tipo = filtros.get('tipoDocId')
            if f_tipo:
                query_docs = query_docs.filter(Documento.tipo_documento_id == f_tipo)
                
            f_desde = filtros.get('fechaInicio')
            if f_desde:
                query_docs = query_docs.filter(Documento.fecha >= f_desde)
                
            f_hasta = filtros.get('fechaFin')
            if f_hasta:
                query_docs = query_docs.filter(Documento.fecha <= f_hasta)

        docs = query_docs.all()
        print(f"‚úÖ [EXPORT] Documentos encontrados: {len(docs)} (Conta={transacciones_conta_flag}, Inv={transacciones_inv_flag})")

        for d in docs:
            doc_packet = {
                "tipo_doc_codigo": d.tipo_documento.codigo, "numero": d.numero,
                "fecha": d.fecha.isoformat() if d.fecha else None,
                "tercero_nit": d.beneficiario.nit if d.beneficiario else None,
                "centro_costo_codigo": d.centro_costo.codigo if d.centro_costo else None,
                "anulado": d.anulado, "observaciones": getattr(d, 'observaciones', None),
                "movimientos_contables": [], "movimientos_inventario": []
            }
            
            # --- SOLO SI SE PIDI√ì CONTABILIDAD ---
            if transacciones_conta_flag:
                for m in d.movimientos:
                    doc_packet["movimientos_contables"].append({
                        "cuenta_codigo": m.cuenta.codigo, 
                        "debito": float(m.debito or 0), "credito": float(m.credito or 0), 
                        "concepto": m.concepto,
                        "producto_codigo": m.producto.codigo if m.producto else None,
                        "cantidad": float(m.cantidad or 0)
                    })

            # --- SOLO SI SE PIDI√ì INVENTARIO ---
            if transacciones_inv_flag:
                movs_inv = db.query(MovimientoInventario).filter(MovimientoInventario.documento_id == d.id).all()
                for mi in movs_inv:
                    doc_packet["movimientos_inventario"].append({
                        "producto_codigo": mi.producto.codigo, "bodega_nombre": mi.bodega.nombre,
                        "tipo": mi.tipo_movimiento, "cantidad": float(mi.cantidad),
                        "costo_unitario": float(mi.costo_unitario), "costo_total": float(mi.costo_total)
                    })
                    
            backup_data["transacciones"].append(doc_packet)

    # --- FIRMA DIGITAL ---
    signature = compute_signature(backup_data)
    signed_backup = {
        "data": backup_data,
        "signature": signature
    }
    
    return signed_backup

# =====================================================================================
# 2. MOTOR DE AN√ÅLISIS
# =====================================================================================
def analizar_backup(db: Session, analysis_request: schemas_migracion.AnalysisRequest):
    backup_data_wrapper = analysis_request.backupData
    target_empresa_id = analysis_request.targetEmpresaId
    
    # 1. Validar Firma
    data = backup_data_wrapper.get("data")
    signature = backup_data_wrapper.get("signature")
    
    if not data or not signature:
        # Soporte para backups antiguos (sin firma) - Opcional: Rechazar o Advertir
        # Por seguridad estricta, rechazamos.
        raise HTTPException(status_code=400, detail="El archivo de backup no tiene firma digital o formato v√°lido.")
        
    computed_signature = compute_signature(data)
    integrity_valid = True
    if not hmac.compare_digest(computed_signature, signature):
        # En v7.0 permitimos an√°lisis incluso si la firma falla, para diagnosticar
        integrity_valid = False
        print("‚ö†Ô∏è [WARNING] Firma digital inv√°lida en Backup. Se procede condicionallmente.")

    # 2. Proceder con el an√°lisis usando 'data' (el contenido real)
    backup_data = data
    
    # 3. Detectar versi√≥n del backup y aplicar compatibilidad
    version_backup = backup_data.get("metadata", {}).get("version_sistema", "7.0")
    compatibilidad = verificar_compatibilidad_version(version_backup)
    
    report = {
        "summary": {}, 
        "conflicts": {"documentos": [], "maestros_faltantes": []}, 
        "sourceEmpresaId": backup_data.get("metadata", {}).get("empresa_id_origen"), 
        "targetEmpresaId": target_empresa_id,
        "integrity_valid": integrity_valid,
        "version_backup": version_backup,
        "compatibilidad": compatibilidad
    }
    
    maestros_map = {
        'terceros': (Tercero, 'nit', 'nit', 'maestros'),
        'plan_cuentas': (PlanCuenta, 'codigo', 'codigo', 'maestros'),
        'centros_costo': (CentroCosto, 'codigo', 'codigo', 'maestros'),
        'tipos_documento': (TipoDocumento, 'codigo', 'codigo', 'maestros'),
        'bodegas': (Bodega, 'nombre', 'nombre', 'inventario'),
        'grupos': (GrupoInventario, 'nombre', 'nombre', 'inventario'),
        'impuestos': (TasaImpuesto, 'nombre', 'nombre', 'inventario'),
        'listas_precio': (ListaPrecio, 'nombre', 'nombre', 'inventario'),
        'productos': (Producto, 'codigo', 'codigo', 'inventario'),
        'formatos_impresion': (FormatoImpresion, 'nombre', 'nombre', 'configuracion'),
        'plantillas': (PlantillaMaestra, 'nombre_plantilla', 'nombre', 'configuracion'),
        'conceptos_favoritos': (ConceptoFavorito, 'descripcion', 'descripcion', 'configuracion'),
        'categorias_activos': (ActivoCategoria, 'nombre', 'nombre', 'activos_fijos'),
        'activos_fijos': (ActivoFijo, 'codigo', 'codigo', 'activos_fijos')
    }

    for key_reporte, (model, db_key, json_key, section) in maestros_map.items():
        source_items = []
        if section in backup_data and key_reporte in backup_data[section]:
            source_items = backup_data[section][key_reporte]
        elif key_reporte in backup_data:
            source_items = backup_data[key_reporte]
        if not source_items: continue
        
        target_rows = db.query(getattr(model, db_key)).filter(getattr(model, 'empresa_id', None) == target_empresa_id).all()
        target_keys = {str(getattr(row, db_key)).strip() for row in target_rows}
        
        # Robust check: Ensure item is a dict before accessing .get()
        a_crear = sum(1 for item in source_items if isinstance(item, dict) and str(item.get(json_key, '')).strip() not in target_keys)
        coincidencias = len(source_items) - a_crear
        
        titulos = {
            'grupos': 'Grupos Inventario', 'impuestos': 'Tasas Impuesto', 'plantillas': 'Plantillas Contables',
            'formatos_impresion': 'Formatos PDF', 'plan_cuentas': 'Plan de Cuentas', 'centros_costo': 'Centros de Costo',
            'conceptos_favoritos': 'Conceptos Favoritos', 'terceros': 'Terceros', 'bodegas': 'Bodegas', 'productos': 'Productos'
        }
        report["summary"][titulos.get(key_reporte, key_reporte)] = {"total": len(source_items), "a_crear": a_crear, "coincidencias": coincidencias}

    cupos_source = backup_data.get("configuracion", {}).get("cupos_adicionales", [])
    if cupos_source:
        target_cupos = db.query(CupoAdicional).filter(CupoAdicional.empresa_id == target_empresa_id).all()
        target_keys_cupos = {f"{c.anio}-{c.mes}" for c in target_cupos}
        a_crear_cupos = sum(1 for c in cupos_source if f"{c['anio']}-{c['mes']}" not in target_keys_cupos)
        report["summary"]["Cupos Mensuales"] = {"total": len(cupos_source), "a_crear": a_crear_cupos, "coincidencias": len(cupos_source) - a_crear_cupos}

    # AN√ÅLISIS DE DOCUMENTOS
    docs_source = backup_data.get("transacciones") or backup_data.get("documentos") or []
    if docs_source:
        sq_totales = db.query(
            MovimientoContable.documento_id,
            func.sum(MovimientoContable.debito).label('total_debito')
        ).group_by(MovimientoContable.documento_id).subquery()

        existing_docs_query = db.query(
            Documento.id,
            Documento.tipo_documento_id,
            Documento.numero,
            func.coalesce(sq_totales.c.total_debito, 0).label('total_debito')
        ).outerjoin(sq_totales, Documento.id == sq_totales.c.documento_id)\
         .filter(Documento.empresa_id == target_empresa_id).all()

        # En an√°lisis no hacemos nada cr√≠tico, solo reportamos
        a_importar_o_corregir = len(docs_source)
        report["summary"]["Documentos y Movimientos"] = {
            "total": len(docs_source), "a_crear": a_importar_o_corregir, "coincidencias": 0
        }

    # AN√ÅLISIS DE PROPIEDAD HORIZONTAL
    ph_data = backup_data.get("propiedad_horizontal", {})
    if ph_data:
        # Conceptos
        if "conceptos" in ph_data:
            c_src = ph_data["conceptos"]
            c_existing = {c.nombre for c in db.query(PHConcepto).filter(PHConcepto.empresa_id == target_empresa_id).all()}
            a_crear = sum(1 for c in c_src if c["nombre"] not in c_existing)
            report["summary"]["PH Conceptos"] = {"total": len(c_src), "a_crear": a_crear, "coincidencias": len(c_src) - a_crear}
        
        # Torres (y Unidades impl√≠citas en total)
        if "torres" in ph_data:
            t_src = ph_data["torres"]
            t_existing = {t.nombre for t in db.query(PHTorre).filter(PHTorre.empresa_id == target_empresa_id).all()}
            a_crear = sum(1 for t in t_src if t["nombre"] not in t_existing)
            report["summary"]["PH Torres"] = {"total": len(t_src), "a_crear": a_crear, "coincidencias": len(t_src) - a_crear}

    # AN√ÅLISIS DE FAVORITOS USUARIO
    fav_src = backup_data.get("configuracion", {}).get("user_favoritos", [])
    if fav_src:
        report["summary"]["Favoritos de Usuario"] = {"total": len(fav_src), "a_crear": len(fav_src), "coincidencias": 0}

    # AN√ÅLISIS DE COTIZACIONES
    cotizaciones_data = backup_data.get("cotizaciones", {})
    if cotizaciones_data:
        if "cotizaciones" in cotizaciones_data:
            c_src = cotizaciones_data["cotizaciones"]
            c_existing = {c.numero for c in db.query(Cotizacion).filter(Cotizacion.empresa_id == target_empresa_id).all()}
            a_crear = sum(1 for c in c_src if c.get("numero") not in c_existing)
            report["summary"]["Cotizaciones"] = {"total": len(c_src), "a_crear": a_crear, "coincidencias": len(c_src) - a_crear}

    # AN√ÅLISIS DE PRODUCCI√ìN
    produccion_data = backup_data.get("produccion", {})
    if produccion_data:
        # Recetas
        if "recetas" in produccion_data:
            r_src = produccion_data["recetas"]
            r_existing = {r.nombre for r in db.query(Receta).filter(Receta.empresa_id == target_empresa_id).all()}
            a_crear = sum(1 for r in r_src if r.get("nombre") not in r_existing)
            report["summary"]["Recetas de Producci√≥n"] = {"total": len(r_src), "a_crear": a_crear, "coincidencias": len(r_src) - a_crear}
        
        # √ìrdenes de Producci√≥n
        if "ordenes" in produccion_data:
            o_src = produccion_data["ordenes"]
            o_existing = {o.numero_orden for o in db.query(OrdenProduccion).filter(OrdenProduccion.empresa_id == target_empresa_id).all()}
            a_crear = sum(1 for o in o_src if o.get("numero_orden") not in o_existing)
            report["summary"]["√ìrdenes de Producci√≥n"] = {"total": len(o_src), "a_crear": a_crear, "coincidencias": len(o_src) - a_crear}

    # AN√ÅLISIS DE CONCILIACI√ìN BANCARIA
    conciliacion_data = backup_data.get("conciliacion_bancaria", {})
    if conciliacion_data:
        # Configuraciones de Importaci√≥n
        if "configuraciones_importacion" in conciliacion_data:
            ci_src = conciliacion_data["configuraciones_importacion"]
            ci_existing = {c.name for c in db.query(ImportConfig).filter(ImportConfig.empresa_id == target_empresa_id).all()}
            a_crear = sum(1 for c in ci_src if c.get("name") not in ci_existing)
            report["summary"]["Configuraciones de Importaci√≥n Bancaria"] = {"total": len(ci_src), "a_crear": a_crear, "coincidencias": len(ci_src) - a_crear}
        
        # Sesiones de Importaci√≥n
        if "sesiones_importacion" in conciliacion_data:
            si_src = conciliacion_data["sesiones_importacion"]
            si_existing = {s.id for s in db.query(ImportSession).filter(ImportSession.empresa_id == target_empresa_id).all()}
            a_crear = sum(1 for s in si_src if s.get("id") not in si_existing)
            report["summary"]["Sesiones de Importaci√≥n Bancaria"] = {"total": len(si_src), "a_crear": a_crear, "coincidencias": len(si_src) - a_crear}
        
        # Movimientos Bancarios
        if "movimientos_bancarios" in conciliacion_data:
            mb_src = conciliacion_data["movimientos_bancarios"]
            report["summary"]["Movimientos Bancarios"] = {"total": len(mb_src), "a_crear": len(mb_src), "coincidencias": 0}
        
        # Conciliaciones
        if "conciliaciones" in conciliacion_data:
            conc_src = conciliacion_data["conciliaciones"]
            report["summary"]["Conciliaciones Bancarias"] = {"total": len(conc_src), "a_crear": len(conc_src), "coincidencias": 0}

    return report

# =====================================================================================
# 3. MOTOR DE RESTAURACI√ìN (ATOMICIDAD TOTAL v7.0 - Modo Fusi√≥n Segura)
# =====================================================================================
def ejecutar_restauracion(db: Session, request: schemas_migracion.AnalysisRequest, user_id: int):
    backup_data_wrapper = request.backupData
    target_empresa_id = request.targetEmpresaId
    modules_to_restore = request.modulesToRestore # Lista opcional de m√≥dulos seleccionados

    # 0. Validar Existencia de Empresa Destino
    empresa_exists = db.query(Empresa).filter(Empresa.id == target_empresa_id).first()
    if not empresa_exists:
        raise HTTPException(status_code=404, detail=f"La empresa destino con ID {target_empresa_id} no existe. Por favor recargue la p√°gina o seleccione una empresa v√°lida.")
    
    # 1. Validar Firma (Nuevamente, por seguridad)
    data = backup_data_wrapper.get("data")
    signature = backup_data_wrapper.get("signature")
    
    if not data or not signature:
        raise HTTPException(status_code=400, detail="El archivo de backup no tiene firma digital.")
        
    computed_signature = compute_signature(data)
    if not hmac.compare_digest(computed_signature, signature):
        if not request.bypass_signature:
            raise HTTPException(status_code=400, detail="ERROR CR√çTICO: Firma inv√°lida. El archivo ha sido modificado o la llave no coincide. Use permisos de administrador para forzar.")
        
    backup_data = data
    
    # 2. Verificar compatibilidad y migrar si es necesario
    version_backup = backup_data.get("metadata", {}).get("version_sistema", "7.0")
    compatibilidad = verificar_compatibilidad_version(version_backup)
    
    if not compatibilidad['compatible']:
        if compatibilidad['requiere_migracion']:
            raise HTTPException(status_code=400, detail=compatibilidad['mensaje'])
        else:
            raise HTTPException(status_code=400, detail=f"Backup incompatible: {compatibilidad['mensaje']}")
    
    # Migrar autom√°ticamente si es necesario
    if version_backup != "7.6":
        backup_data = migrar_backup_version(backup_data, version_backup, "7.6")
    
    resumen = {
        "acciones_realizadas": [],
        "maestros_actualizados": 0,
        "documentos_procesados": 0,
        "version_backup": version_backup,
        "compatibilidad": compatibilidad['mensaje']
    }

    # --- FASE 0: CINTUR√ìN DE SEGURIDAD ---
    try:
        print(f"üöÄ INICIANDO PROTOCOLO ESPEJO AT√ìMICO v7.0 PARA EMPRESA {target_empresa_id}")
        
        safety_snapshot = generar_backup_json(db, target_empresa_id)
        filename = f"SAFETY_RESTORE_{target_empresa_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        os.makedirs("backups/safety", exist_ok=True)
        with open(f"backups/safety/{filename}", "w", encoding="utf-8") as f:
            json.dump(safety_snapshot, f, cls=AlchemyEncoder)
            
        resumen["acciones_realizadas"].append(f"üîí Snapshot de seguridad creado: {filename}")

        # 1. RESTAURAR CONFIGURACI√ìN DE EMPRESA
        empresa = db.query(Empresa).filter(Empresa.id == target_empresa_id).first()
        if "empresa" in backup_data and empresa:
            emp_data = backup_data["empresa"]
            # BLOQUEADO: No sobreescribir datos de la empresa destino al restaurar.
            # Se preserva la identidad (Nit, Direcci√≥n, etc.) de la empresa que recibe el PUC.
            # for field in ["direccion", "telefono", "email", "logo_url"]:
            #     if field in emp_data: setattr(empresa, field, emp_data[field])
            # db.add(empresa)

        # 2. RESTAURAR CUPOS (BLOQUEADO POR SEGURIDAD)
        # No se deben transferir cupos adicionales entre empresas. Cada empresa mantiene sus propios cupos comprados.
        # if "cupos_adicionales" in backup_data.get("configuracion", {}):
        #     db.query(CupoAdicional).filter(CupoAdicional.empresa_id == target_empresa_id).delete()
        #     for c in backup_data["configuracion"]["cupos_adicionales"]:
        #         db.add(CupoAdicional(empresa_id=target_empresa_id, anio=c["anio"], mes=c["mes"], cantidad_adicional=c["cantidad"]))

        # 3. MAESTROS
        maestros_src = backup_data.get("maestros", {})
        inv_src = backup_data.get("inventario", {})
        
        # Helper check function
        def should_restore(module_key):
             # Si no se especifica lista, se restaura TODO (comportamiento legacy/default)
             if not modules_to_restore: return True
             return module_key in modules_to_restore

        # Restaurar Listas de Precio PRIMERO
        if should_restore('Listas de Precio'):
            _upsert_manual_seguro(db, ListaPrecio, 'listas_precio', 'nombre', inv_src, target_empresa_id, user_id)
            db.flush()
        
        map_listas = _get_id_translation_map(db, ListaPrecio, 'nombre', inv_src, target_empresa_id)

        # Restauraci√≥n de Terceros (ID MAP BLINDADO)
        # Restauraci√≥n de Terceros (ID MAP BLINDADO)
        if should_restore('Terceros'):
            _upsert_manual_seguro(db, Tercero, 'terceros', 'nit', maestros_src, target_empresa_id, user_id, id_maps={'lista_precio_id': map_listas})
        
        if should_restore('Bodegas'):
             _upsert_manual_seguro(db, Bodega, 'bodegas', 'nombre', inv_src, target_empresa_id, user_id)

        if should_restore('Plan de Cuentas'):
            _restore_jerarquico(db, PlanCuenta, 'plan_cuentas', 'cuenta_padre_id', maestros_src, target_empresa_id, user_id)

        if should_restore('Centros de Costo'):
            _restore_jerarquico(db, CentroCosto, 'centros_costo', 'centro_costo_padre_id', maestros_src, target_empresa_id, user_id)
        db.flush()

        map_cuentas = _get_id_translation_map(db, PlanCuenta, 'codigo', maestros_src, target_empresa_id)
        map_ccs = _get_id_translation_map(db, CentroCosto, 'codigo', maestros_src, target_empresa_id)
        map_terceros = _get_id_translation_map(db, Tercero, 'nit', maestros_src, target_empresa_id)
        map_bodegas = _get_id_translation_map(db, Bodega, 'nombre', inv_src, target_empresa_id)
        
        config_src = backup_data.get("configuracion", {})
        if should_restore('Conceptos Favoritos'):
            _upsert_manual_seguro(db, ConceptoFavorito, 'conceptos_favoritos', 'descripcion', config_src, target_empresa_id, user_id, id_maps={"centro_costo_id": map_ccs})

        id_maps_tipos = {
            "cuenta_caja_id": map_cuentas, 
            "cuenta_debito_cxc_id": map_cuentas, "cuenta_credito_cxc_id": map_cuentas,
            "cuenta_debito_cxp_id": map_cuentas, "cuenta_credito_cxp_id": map_cuentas
        }
        if should_restore('Tipos de Documento'):
            _upsert_manual_seguro(db, TipoDocumento, 'tipos_documento', 'codigo', maestros_src, target_empresa_id, user_id, id_maps=id_maps_tipos)
        
        # --- 0. IMPUESTOS (Movido antes de grupos para dependencia) ---
        # --- 0. IMPUESTOS (Movido antes de grupos para dependencia) ---
        id_maps_impuestos = {"cuenta_id": map_cuentas, "cuenta_iva_descontable_id": map_cuentas}
        if should_restore('Tasas Impuesto'):
            _upsert_manual_seguro(db, TasaImpuesto, 'tasas_impuesto', 'nombre', inv_src, target_empresa_id, user_id, id_maps=id_maps_impuestos)
        db.flush()
        
        map_impuestos = _get_id_translation_map(db, TasaImpuesto, 'nombre', inv_src, target_empresa_id)

        # --- RESTAURACI√ìN DE GRUPOS ---
        if "grupos" in inv_src:
            for g in inv_src["grupos"]:
                if "cuentas" in g and isinstance(g["cuentas"], dict):
                    ctas = g["cuentas"]
                    if "inventario" in ctas: g["cuenta_inventario_codigo"] = ctas["inventario"]
                    if "ingreso" in ctas: g["cuenta_ingreso_codigo"] = ctas["ingreso"]
                    if "costo" in ctas: g["cuenta_costo_venta_codigo"] = ctas["costo"]
                    if "faltante" in ctas: g["cuenta_ajuste_faltante_codigo"] = ctas["faltante"]
                    if "sobrante" in ctas: g["cuenta_ajuste_sobrante_codigo"] = ctas["sobrante"]

        id_maps_grupos = {
            "cuenta_inventario_id": map_cuentas, "cuenta_ingreso_id": map_cuentas, "cuenta_costo_venta_id": map_cuentas,
            "cuenta_ajuste_faltante_id": map_cuentas, "cuenta_ajuste_sobrante_id": map_cuentas,
            "impuesto_predeterminado_id": map_impuestos
        }
        if should_restore('Grupos Inventario'):
             _upsert_manual_seguro(db, GrupoInventario, 'grupos', 'nombre', inv_src, target_empresa_id, user_id, id_maps=id_maps_grupos)
        db.flush()
        
        # Sub-tablas de Grupos
        if "grupos" in inv_src:
            if not map_listas:
                listas_db = db.query(ListaPrecio).filter(ListaPrecio.empresa_id == target_empresa_id).all()
                map_listas = {l.nombre: l.id for l in listas_db}

            target_grupos = db.query(GrupoInventario).filter(GrupoInventario.empresa_id == target_empresa_id).all()
            map_grupos_obj = {g.nombre: g for g in target_grupos}

            for grp_data in inv_src["grupos"]:
                grupo_db = map_grupos_obj.get(grp_data["nombre"])
                if not grupo_db: continue

                if "caracteristicas" in grp_data:
                    subq = db.query(CaracteristicaDefinicion.id).filter(CaracteristicaDefinicion.grupo_inventario_id == grupo_db.id).subquery()
                    # Borrar valores
                    db.query(CaracteristicaValorProducto).filter(CaracteristicaValorProducto.definicion_id.in_(select(subq))).delete(synchronize_session=False)
                    # Borrar definiciones
                    db.query(CaracteristicaDefinicion).filter(CaracteristicaDefinicion.grupo_inventario_id == grupo_db.id).delete(synchronize_session=False)
                    
                    for c in grp_data["caracteristicas"]:
                        db.add(CaracteristicaDefinicion(grupo_inventario_id=grupo_db.id, nombre=c["nombre"], es_unidad_medida=c["es_unidad"]))
                
                if "reglas" in grp_data:
                    # Solo tocamos reglas si estamos restaurando grupos
                    if should_restore('Grupos Inventario'):
                        db.query(ReglaPrecioGrupo).filter(ReglaPrecioGrupo.grupo_inventario_id == grupo_db.id).delete(synchronize_session=False)
                        for r in grp_data["reglas"]:
                            lista_id = map_listas.get(r.get("lista_nombre"))
                            if lista_id:
                                # CORRECCI√ìN: Usar clave correcta 'porcentaje_incremento' (modelo) o fallback a 'porcentaje'
                                p_inc = r.get("porcentaje_incremento", r.get("porcentaje", 0))
                                db.add(ReglaPrecioGrupo(grupo_inventario_id=grupo_db.id, lista_precio_id=lista_id, porcentaje_incremento=p_inc))

        # --- PRODUCTOS (Impuestos ya restaurados antes de grupos) ---
        map_grupos = _get_id_translation_map(db, GrupoInventario, 'nombre', inv_src, target_empresa_id)
        # map_impuestos ya fue calculado arriba
        if should_restore('Productos'):
            _upsert_manual_seguro(db, Producto, 'productos', 'codigo', inv_src, target_empresa_id, user_id, id_maps={"grupo_id": map_grupos, "impuesto_iva_id": map_impuestos})
        db.flush()
        map_productos = _get_id_translation_map(db, Producto, 'codigo', inv_src, target_empresa_id)

        # 5. FORMATOS Y PLANTILLAS
        if "formatos_impresion" in config_src:
            # Eliminar formatos existentes (defaults) para evitar colisi√≥n de Nombres √önicos
            db.query(FormatoImpresion).filter(FormatoImpresion.empresa_id == target_empresa_id).delete()
            db.flush()

            map_tipos_final = _get_id_translation_map(db, TipoDocumento, 'codigo', maestros_src, target_empresa_id)
            id_maps_fmt = {"tipo_documento_id": map_tipos_final}
            
            # Modificar nombres para garantizar unicidad global (la tabla tiene unique en nombre)
            for fmt in config_src["formatos_impresion"]:
                if "nombre" in fmt:
                    # Append suffix only if not present (though restoring usually brings clean names)
                    suffix = f" - {target_empresa_id}"
                    if not str(fmt["nombre"]).endswith(suffix):
                        fmt["nombre"] = f"{fmt['nombre']}{suffix}"

            if should_restore('Formatos PDF'):
                 _upsert_manual_seguro(db, FormatoImpresion, 'formatos_impresion', 'nombre', config_src, target_empresa_id, user_id, id_maps=id_maps_fmt)

        if "plantillas" in config_src and should_restore('Plantillas Contables'):
            db.query(PlantillaMaestra).filter(PlantillaMaestra.empresa_id == target_empresa_id).delete(synchronize_session=False)
            db.flush()
            for p in config_src["plantillas"]:
                maestra = PlantillaMaestra(empresa_id=target_empresa_id, nombre_plantilla=p["nombre"], created_at=datetime.utcnow(), created_by=user_id)
                db.add(maestra)
                db.flush()
                for d in p["detalles"]:
                    cuenta_id = map_cuentas.get(d["cuenta_codigo"])
                    cc_id = map_ccs.get(d.get("centro_costo_codigo"))
                    if cuenta_id:
                        db.add(PlantillaDetalle(plantilla_maestra_id=maestra.id, cuenta_id=cuenta_id, centro_costo_id=cc_id, concepto=d["concepto"], debito=d["debito"], credito=d["credito"]))
        db.flush()

        # 6. M√ìDULOS ESPECIALIZADOS
        
        # --- PROPIEDAD HORIZONTAL ---
        ph_data = backup_data.get("propiedad_horizontal", {})
        if ph_data and should_restore('Propiedad Horizontal'):
            # Config
            if "configuracion" in ph_data:
                conf_data = ph_data["configuracion"]
                # Upsert PH Config
                ph_conf = db.query(PHConfiguracion).filter(PHConfiguracion.empresa_id == target_empresa_id).first()
                if not ph_conf:
                    ph_conf = PHConfiguracion(empresa_id=target_empresa_id)
                    db.add(ph_conf)
                # Actualizar campos simples
                # Generar mapas de traducci√≥n de ID (Old ID -> New ID)
                map_tipos_code = _get_id_translation_map(db, TipoDocumento, 'codigo', maestros_src, target_empresa_id)
                map_tipos_id = {}
                for item in maestros_src.get('tipos_documento', []):
                    if str(item.get('codigo')) in map_tipos_code:
                        map_tipos_id[str(item['id'])] = map_tipos_code[str(item['codigo'])]

                map_cuentas_id = {}
                for item in maestros_src.get('plan_cuentas', []):
                     if str(item.get('codigo')) in map_cuentas:
                         map_cuentas_id[str(item['id'])] = map_cuentas[str(item['codigo'])]

                # Actualizar campos con mapeo
                for k, v in conf_data.items():
                    if not hasattr(ph_conf, k) or k in ['id', 'empresa_id']: continue
                    
                    val_to_set = v
                    
                    # Mapear Foreign Keys
                    if k in ['tipo_documento_factura_id', 'tipo_documento_recibo_id'] and v is not None:
                         val_to_set = map_tipos_id.get(str(v))
                    elif k in ['cuenta_cartera_id', 'cuenta_caja_id', 'cuenta_ingreso_intereses_id'] and v is not None:
                         val_to_set = map_cuentas_id.get(str(v))
                    
                    setattr(ph_conf, k, val_to_set)
            
            # Conceptos
            _upsert_manual_seguro(db, PHConcepto, 'conceptos', 'nombre', ph_data, target_empresa_id, user_id, 
                                id_maps={"cuenta_cxc_id": map_cuentas, "cuenta_caja_id": map_cuentas,
                                         "cuenta_ingreso_id": map_cuentas, "cuenta_interes_id": map_cuentas})
            
            # Torres y Unidades
            if "torres" in ph_data:
                for t_data in ph_data["torres"]:
                    torre = db.query(PHTorre).filter(PHTorre.empresa_id == target_empresa_id, PHTorre.nombre == t_data["nombre"]).first()
                    if not torre:
                        torre = PHTorre(empresa_id=target_empresa_id, nombre=t_data["nombre"])
                        db.add(torre)
                        db.flush()
                    
                    for u_data in t_data["unidades"]:
                        unidad = db.query(PHUnidad).filter(PHUnidad.empresa_id == target_empresa_id, PHUnidad.codigo == u_data["codigo"]).first()
                        prop_id = map_terceros.get(u_data.get("propietario_nit"))
                        arr_id = map_terceros.get(u_data.get("arrendatario_nit"))
                        
                        if not unidad:
                             unidad = PHUnidad(empresa_id=target_empresa_id, torre_id=torre.id, codigo=u_data["codigo"], nombre=u_data["nombre"])
                             db.add(unidad)
                        
                        unidad.coeficiente = u_data["coeficiente"]
                        unidad.propietario_id = prop_id
                        unidad.arrendatario_id = arr_id
            
        # --- ACTIVOS FIJOS ---
        activos_data = backup_data.get("activos_fijos", {})
        if activos_data and should_restore('Activos Fijos'):
             _upsert_manual_seguro(db, ActivoCategoria, 'categorias', 'nombre', activos_data, target_empresa_id, user_id, 
                                   id_maps={'cuenta_activo_id': map_cuentas, 'cuenta_depreciacion_acumulada_id': map_cuentas, 'cuenta_gasto_depreciacion_id': map_cuentas})
             db.flush()
             map_cats = _get_id_translation_map(db, ActivoCategoria, 'nombre', activos_data, target_empresa_id)
             
             # --- AUTO-CREATE MISSING CATEGORIES (Prevent FK Error) ---
             # If an asset refers to a category that wasn't in the categories list (or failed restore), we create it.
             existing_cat_names = set(map_cats.keys())
             cats_to_create = set()
             for a in activos_data.get("activos", []):
                 c_name = str(a.get("categoria_nombre", "")).strip()
                 if c_name and c_name not in existing_cat_names:
                     cats_to_create.add(c_name)
             
             if cats_to_create:
                 print(f"‚ö†Ô∏è Auto-creating {len(cats_to_create)} missing categories for assets: {cats_to_create}")
                 for c_name in cats_to_create:
                     new_cat = ActivoCategoria(
                         empresa_id=target_empresa_id, 
                         nombre=c_name, 
                         vida_util_niif_meses=60, # Default safe value
                         metodo_depreciacion="LINEA_RECTA"
                     )
                     db.add(new_cat)
                 db.flush()
                 # Rebuild Map
                 map_cats = _get_id_translation_map(db, ActivoCategoria, 'nombre', activos_data, target_empresa_id)
                 # Add newly created ones manually to map if not found by source check (since source didn't have them)
                 for c_name in cats_to_create:
                        # Fetch ID
                        mat_cat = db.query(ActivoCategoria).filter(ActivoCategoria.empresa_id == target_empresa_id, ActivoCategoria.nombre == c_name).first()
                        if mat_cat: map_cats[c_name] = mat_cat.id
 
             _upsert_manual_seguro(db, ActivoFijo, 'activos', 'codigo', activos_data, target_empresa_id, user_id,
                                   id_maps={'categoria_id': map_cats, 'responsable_id': map_terceros, 'centro_costo_id': map_ccs})

        # --- COTIZACIONES ---
        cotizaciones_data = backup_data.get("cotizaciones", {})
        if cotizaciones_data and "cotizaciones" in cotizaciones_data and should_restore('Cotizaciones'):
            for cotiz_data in cotizaciones_data["cotizaciones"]:
                # Mapear dependencias
                tercero_id = map_terceros.get(cotiz_data.get("tercero_nit"))
                bodega_id = None
                if cotiz_data.get("bodega_nombre"):
                    bodega_id = map_bodegas.get(cotiz_data["bodega_nombre"])
                
                usuario_id_cotiz = user_id  # Por defecto usar el usuario actual
                if cotiz_data.get("usuario_email"):
                    usuario_db = db.query(Usuario).filter(Usuario.email == cotiz_data["usuario_email"]).first()
                    if usuario_db:
                        usuario_id_cotiz = usuario_db.id

                # Verificar si la cotizaci√≥n ya existe
                existing_cotiz = db.query(Cotizacion).filter(
                    Cotizacion.empresa_id == target_empresa_id,
                    Cotizacion.numero == cotiz_data["numero"]
                ).first()

                if existing_cotiz:
                    # Actualizar cotizaci√≥n existente
                    cotizacion = existing_cotiz
                    # Limpiar detalles existentes
                    db.query(CotizacionDetalle).filter(CotizacionDetalle.cotizacion_id == cotizacion.id).delete()
                else:
                    # Crear nueva cotizaci√≥n
                    cotizacion = Cotizacion(
                        empresa_id=target_empresa_id,
                        numero=cotiz_data["numero"]
                    )
                    db.add(cotizacion)

                # Actualizar campos de la cotizaci√≥n
                for field in ['fecha', 'fecha_vencimiento', 'estado', 'observaciones', 'total_estimado']:
                    if field in cotiz_data:
                        if field in ['fecha', 'fecha_vencimiento'] and cotiz_data[field]:
                            try:
                                setattr(cotizacion, field, datetime.fromisoformat(cotiz_data[field]).date())
                            except:
                                pass
                        else:
                            setattr(cotizacion, field, cotiz_data[field])

                cotizacion.tercero_id = tercero_id
                cotizacion.bodega_id = bodega_id
                cotizacion.usuario_id = usuario_id_cotiz

                db.flush()  # Para obtener el ID de la cotizaci√≥n

                # Restaurar detalles
                for detalle_data in cotiz_data.get("detalles", []):
                    producto_id = map_productos.get(detalle_data.get("producto_codigo"))
                    if producto_id:
                        detalle = CotizacionDetalle(
                            cotizacion_id=cotizacion.id,
                            producto_id=producto_id,
                            cantidad=detalle_data.get("cantidad", 0),
                            precio_unitario=detalle_data.get("precio_unitario", 0),
                            cantidad_facturada=detalle_data.get("cantidad_facturada", 0)
                        )
                        db.add(detalle)

            resumen["acciones_realizadas"].append(f"üìã Cotizaciones restauradas: {len(cotizaciones_data['cotizaciones'])} cotizaciones procesadas")

        db.flush()

        # --- PRODUCCI√ìN ---
        produccion_data = backup_data.get("produccion", {})
        if produccion_data and should_restore('Producci√≥n'):
            # 1. Restaurar Configuraci√≥n de Producci√≥n
            if "configuracion" in produccion_data:
                config_data = produccion_data["configuracion"]
                prod_config = db.query(ConfiguracionProduccion).filter(ConfiguracionProduccion.empresa_id == target_empresa_id).first()
                if not prod_config:
                    prod_config = ConfiguracionProduccion(empresa_id=target_empresa_id)
                    db.add(prod_config)
                
                # Mapear tipos de documento
                map_tipos_doc = _get_id_translation_map(db, TipoDocumento, 'codigo', maestros_src, target_empresa_id)
                if config_data.get("tipo_documento_orden_codigo"):
                    prod_config.tipo_documento_orden_id = map_tipos_doc.get(config_data["tipo_documento_orden_codigo"])
                if config_data.get("tipo_documento_anulacion_codigo"):
                    prod_config.tipo_documento_anulacion_id = map_tipos_doc.get(config_data["tipo_documento_anulacion_codigo"])
                if config_data.get("tipo_documento_consumo_codigo"):
                    prod_config.tipo_documento_consumo_id = map_tipos_doc.get(config_data["tipo_documento_consumo_codigo"])
                if config_data.get("tipo_documento_entrada_pt_codigo"):
                    prod_config.tipo_documento_entrada_pt_id = map_tipos_doc.get(config_data["tipo_documento_entrada_pt_codigo"])
                
                db.flush()

            # 2. Restaurar Recetas
            if "recetas" in produccion_data:
                for receta_data in produccion_data["recetas"]:
                    producto_id = map_productos.get(receta_data.get("producto_codigo"))
                    if not producto_id:
                        continue  # Skip si no existe el producto

                    # Verificar si la receta ya existe
                    existing_receta = db.query(Receta).filter(
                        Receta.empresa_id == target_empresa_id,
                        Receta.nombre == receta_data["nombre"]
                    ).first()

                    if existing_receta:
                        receta = existing_receta
                        # Limpiar detalles y recursos existentes
                        db.query(RecetaDetalle).filter(RecetaDetalle.receta_id == receta.id).delete()
                        db.query(RecetaRecurso).filter(RecetaRecurso.receta_id == receta.id).delete()
                    else:
                        receta = Receta(
                            empresa_id=target_empresa_id,
                            nombre=receta_data["nombre"]
                        )
                        db.add(receta)

                    # Actualizar campos
                    receta.producto_id = producto_id
                    receta.descripcion = receta_data.get("descripcion")
                    receta.cantidad_base = receta_data.get("cantidad_base", 1.0)
                    receta.activa = receta_data.get("activa", True)

                    db.flush()

                    # Restaurar detalles (insumos)
                    for detalle_data in receta_data.get("detalles", []):
                        insumo_id = map_productos.get(detalle_data.get("insumo_codigo"))
                        if insumo_id:
                            detalle = RecetaDetalle(
                                receta_id=receta.id,
                                insumo_id=insumo_id,
                                cantidad=detalle_data.get("cantidad", 0)
                            )
                            db.add(detalle)

                    # Restaurar recursos
                    for recurso_data in receta_data.get("recursos", []):
                        cuenta_id = None
                        if recurso_data.get("cuenta_contable_codigo"):
                            cuenta_id = map_cuentas.get(recurso_data["cuenta_contable_codigo"])
                        
                        recurso = RecetaRecurso(
                            receta_id=receta.id,
                            descripcion=recurso_data.get("descripcion", ""),
                            tipo=recurso_data.get("tipo", "MOD"),
                            costo_estimado=recurso_data.get("costo_estimado", 0),
                            cuenta_contable_id=cuenta_id
                        )
                        db.add(recurso)

            # 3. Restaurar √ìrdenes de Producci√≥n
            if "ordenes" in produccion_data:
                for orden_data in produccion_data["ordenes"]:
                    producto_id = map_productos.get(orden_data.get("producto_codigo"))
                    bodega_destino_id = map_bodegas.get(orden_data.get("bodega_destino_nombre"))
                    
                    if not producto_id or not bodega_destino_id:
                        continue  # Skip si faltan dependencias cr√≠ticas

                    # Buscar receta por nombre si existe
                    receta_id = None
                    if orden_data.get("receta_nombre"):
                        receta = db.query(Receta).filter(
                            Receta.empresa_id == target_empresa_id,
                            Receta.nombre == orden_data["receta_nombre"]
                        ).first()
                        if receta:
                            receta_id = receta.id

                    # Verificar si la orden ya existe
                    existing_orden = db.query(OrdenProduccion).filter(
                        OrdenProduccion.empresa_id == target_empresa_id,
                        OrdenProduccion.numero_orden == orden_data["numero_orden"]
                    ).first()

                    if existing_orden:
                        orden = existing_orden
                        # Limpiar insumos y recursos existentes
                        db.query(OrdenProduccionInsumo).filter(OrdenProduccionInsumo.orden_id == orden.id).delete()
                        db.query(OrdenProduccionRecurso).filter(OrdenProduccionRecurso.orden_id == orden.id).delete()
                    else:
                        orden = OrdenProduccion(
                            empresa_id=target_empresa_id,
                            numero_orden=orden_data["numero_orden"]
                        )
                        db.add(orden)

                    # Actualizar campos
                    orden.producto_id = producto_id
                    orden.receta_id = receta_id
                    orden.bodega_destino_id = bodega_destino_id
                    orden.cantidad_planeada = orden_data.get("cantidad_planeada", 0)
                    orden.cantidad_real = orden_data.get("cantidad_real", 0)
                    orden.estado = orden_data.get("estado", "PLANIFICADA")
                    orden.observaciones = orden_data.get("observaciones")
                    orden.archivada = orden_data.get("archivada", False)
                    orden.motivo_anulacion = orden_data.get("motivo_anulacion")
                    
                    # Fechas
                    if orden_data.get("fecha_inicio"):
                        try:
                            orden.fecha_inicio = datetime.fromisoformat(orden_data["fecha_inicio"]).date()
                        except:
                            pass
                    if orden_data.get("fecha_fin"):
                        try:
                            orden.fecha_fin = datetime.fromisoformat(orden_data["fecha_fin"]).date()
                        except:
                            pass

                    # Costos
                    orden.costo_total_mp = orden_data.get("costo_total_mp", 0)
                    orden.costo_total_mod = orden_data.get("costo_total_mod", 0)
                    orden.costo_total_cif = orden_data.get("costo_total_cif", 0)
                    orden.costo_unitario_final = orden_data.get("costo_unitario_final", 0)

                    db.flush()

                    # Restaurar insumos consumidos
                    for insumo_data in orden_data.get("insumos", []):
                        insumo_id = map_productos.get(insumo_data.get("insumo_codigo"))
                        bodega_origen_id = map_bodegas.get(insumo_data.get("bodega_origen_nombre"))
                        
                        if insumo_id and bodega_origen_id:
                            insumo = OrdenProduccionInsumo(
                                orden_id=orden.id,
                                insumo_id=insumo_id,
                                bodega_origen_id=bodega_origen_id,
                                cantidad=insumo_data.get("cantidad", 0),
                                costo_unitario_historico=insumo_data.get("costo_unitario_historico", 0),
                                costo_total=insumo_data.get("costo_total", 0)
                            )
                            if insumo_data.get("fecha_despacho"):
                                try:
                                    insumo.fecha_despacho = datetime.fromisoformat(insumo_data["fecha_despacho"])
                                except:
                                    pass
                            db.add(insumo)

                    # Restaurar recursos utilizados
                    for recurso_data in orden_data.get("recursos", []):
                        recurso = OrdenProduccionRecurso(
                            orden_id=orden.id,
                            descripcion=recurso_data.get("descripcion", ""),
                            tipo=recurso_data.get("tipo", "MOD"),
                            valor=recurso_data.get("valor", 0)
                        )
                        if recurso_data.get("fecha_registro"):
                            try:
                                recurso.fecha_registro = datetime.fromisoformat(recurso_data["fecha_registro"])
                            except:
                                pass
                        db.add(recurso)

            # Contar elementos restaurados para el resumen
            recetas_count = len(produccion_data.get("recetas", []))
            ordenes_count = len(produccion_data.get("ordenes", []))
            if recetas_count > 0 or ordenes_count > 0:
                resumen["acciones_realizadas"].append(f"üè≠ Producci√≥n restaurada: {recetas_count} recetas, {ordenes_count} √≥rdenes de producci√≥n")

        db.flush()

        # --- CONCILIACI√ìN BANCARIA ---
        conciliacion_data = backup_data.get("conciliacion_bancaria", {})
        if conciliacion_data and should_restore('Conciliaci√≥n Bancaria'):
            # 1. Restaurar Configuraciones de Importaci√≥n
            map_import_configs = {} # Mapa OldID -> NewID
            
            if "configuraciones_importacion" in conciliacion_data:
                for config_data in conciliacion_data["configuraciones_importacion"]:
                    bank_id = map_terceros.get(config_data.get("bank_nit"))
                    creator_id = user_id  # Por defecto usar el usuario actual
                    updater_id = user_id
                    
                    if config_data.get("creator_email"):
                        creator = db.query(Usuario).filter(Usuario.email == config_data["creator_email"]).first()
                        if creator:
                            creator_id = creator.id
                    
                    if config_data.get("updater_email"):
                        updater = db.query(Usuario).filter(Usuario.email == config_data["updater_email"]).first()
                        if updater:
                            updater_id = updater.id

                    # Verificar si la configuraci√≥n ya existe
                    existing_config = db.query(ImportConfig).filter(
                        ImportConfig.empresa_id == target_empresa_id,
                        ImportConfig.name == config_data["name"]
                    ).first()

                    if existing_config:
                        config = existing_config
                    else:
                        config = ImportConfig(
                            empresa_id=target_empresa_id,
                            name=config_data["name"]
                        )
                        db.add(config)

                    # Actualizar campos
                    config.bank_id = bank_id
                    config.file_format = config_data.get("file_format", "CSV")
                    config.delimiter = config_data.get("delimiter", ",")
                    config.date_format = config_data.get("date_format", "%Y-%m-%d")
                    config.field_mapping = config_data.get("field_mapping", {})
                    config.header_rows = config_data.get("header_rows", 1)
                    config.is_active = config_data.get("is_active", True)
                    config.created_by = creator_id
                    config.updated_by = updater_id
                    
                    db.flush() # Importante: Generar ID
                    
                    # Guardar mapeo si tiene ID origen (para ImportSession)
                    if "id" in config_data:
                        map_import_configs[str(config_data["id"])] = config.id
                        
            # 2. Restaurar Configuraciones Contables
            if "configuraciones_contables" in conciliacion_data:
                for acc_config_data in conciliacion_data["configuraciones_contables"]:
                    bank_account_id = map_cuentas.get(acc_config_data.get("bank_account_codigo"))
                    if not bank_account_id:
                        continue  # Skip si no existe la cuenta bancaria

                    creator_id = user_id
                    updater_id = user_id
                    
                    if acc_config_data.get("creator_email"):
                        creator = db.query(Usuario).filter(Usuario.email == acc_config_data["creator_email"]).first()
                        if creator:
                            creator_id = creator.id
                    
                    if acc_config_data.get("updater_email"):
                        updater = db.query(Usuario).filter(Usuario.email == acc_config_data["updater_email"]).first()
                        if updater:
                            updater_id = updater.id

                    # Verificar si la configuraci√≥n ya existe
                    existing_acc_config = db.query(AccountingConfig).filter(
                        AccountingConfig.empresa_id == target_empresa_id,
                        AccountingConfig.bank_account_id == bank_account_id
                    ).first()

                    if existing_acc_config:
                        acc_config = existing_acc_config
                    else:
                        acc_config = AccountingConfig(
                            empresa_id=target_empresa_id,
                            bank_account_id=bank_account_id
                        )
                        db.add(acc_config)

                    # Mapear cuentas contables
                    acc_config.commission_account_id = map_cuentas.get(acc_config_data.get("commission_account_codigo"))
                    acc_config.interest_income_account_id = map_cuentas.get(acc_config_data.get("interest_income_account_codigo"))
                    acc_config.bank_charges_account_id = map_cuentas.get(acc_config_data.get("bank_charges_account_codigo"))
                    acc_config.adjustment_account_id = map_cuentas.get(acc_config_data.get("adjustment_account_codigo"))
                    acc_config.default_cost_center_id = map_ccs.get(acc_config_data.get("default_cost_center_codigo"))
                    acc_config.is_active = acc_config_data.get("is_active", True)
                    acc_config.created_by = creator_id
                    acc_config.updated_by = updater_id

            # 3. Restaurar Sesiones de Importaci√≥n
            if "sesiones_importacion" in conciliacion_data:
                for session_data in conciliacion_data["sesiones_importacion"]:
                    bank_account_id = map_cuentas.get(session_data.get("bank_account_codigo"))
                    user_session_id = user_id
                    
                    if session_data.get("user_email"):
                        user_session = db.query(Usuario).filter(Usuario.email == session_data["user_email"]).first()
                        if user_session:
                            user_session_id = user_session.id
                    
                    # Mapear import_config_id usando el mapa generado
                    import_config_id = None
                    if session_data.get("import_config_id"):
                         import_config_id = map_import_configs.get(str(session_data["import_config_id"]))

                    # Verificar si la sesi√≥n ya existe
                    existing_session = db.query(ImportSession).filter(
                        ImportSession.id == session_data["id"]
                    ).first()

                    if not existing_session and bank_account_id:
                        session = ImportSession(
                            id=session_data["id"],
                            empresa_id=target_empresa_id,
                            bank_account_id=bank_account_id,
                            file_name=session_data.get("file_name", ""),
                            file_hash=session_data.get("file_hash", ""),
                            import_config_id=import_config_id,
                            total_movements=session_data.get("total_movements", 0),
                            successful_imports=session_data.get("successful_imports", 0),
                            errors=session_data.get("errors"),
                            user_id=user_session_id,
                            status=session_data.get("status", "COMPLETED")
                        )
                        if session_data.get("import_date"):
                            try:
                                session.import_date = datetime.fromisoformat(session_data["import_date"])
                            except:
                                pass
                        db.add(session)

            # 4. Restaurar Movimientos Bancarios
            if "movimientos_bancarios" in conciliacion_data:
                for movement_data in conciliacion_data["movimientos_bancarios"]:
                    bank_account_id = map_cuentas.get(movement_data.get("bank_account_codigo"))
                    if not bank_account_id:
                        continue

                    # Los movimientos bancarios normalmente no se duplican por ID, 
                    # pero podemos verificar por combinaci√≥n de campos √∫nicos
                    existing_movement = db.query(BankMovement).filter(
                        BankMovement.empresa_id == target_empresa_id,
                        BankMovement.import_session_id == movement_data.get("import_session_id"),
                        BankMovement.reference == movement_data.get("reference"),
                        BankMovement.amount == movement_data.get("amount")
                    ).first()

                    if not existing_movement:
                        movement = BankMovement(
                            empresa_id=target_empresa_id,
                            import_session_id=movement_data.get("import_session_id"),
                            bank_account_id=bank_account_id,
                            amount=movement_data.get("amount", 0),
                            description=movement_data.get("description", ""),
                            reference=movement_data.get("reference"),
                            transaction_type=movement_data.get("transaction_type"),
                            balance=movement_data.get("balance"),
                            status=movement_data.get("status", "PENDING")
                        )
                        
                        # Fechas
                        if movement_data.get("transaction_date"):
                            try:
                                movement.transaction_date = datetime.fromisoformat(movement_data["transaction_date"]).date()
                            except:
                                pass
                        if movement_data.get("value_date"):
                            try:
                                movement.value_date = datetime.fromisoformat(movement_data["value_date"]).date()
                            except:
                                pass
                        
                        db.add(movement)

            # 5. Restaurar Conciliaciones y Auditor√≠a
            # Nota: Las conciliaciones y auditor√≠a son m√°s complejas y dependen de movimientos contables existentes
            # Por simplicidad, las omitimos en esta implementaci√≥n inicial
            # Se pueden agregar en una versi√≥n futura si es necesario

            # Contar elementos restaurados para el resumen
            configs_count = len(conciliacion_data.get("configuraciones_importacion", []))
            sessions_count = len(conciliacion_data.get("sesiones_importacion", []))
            movements_count = len(conciliacion_data.get("movimientos_bancarios", []))
            if configs_count > 0 or sessions_count > 0 or movements_count > 0:
                resumen["acciones_realizadas"].append(f"üè¶ Conciliaci√≥n Bancaria restaurada: {configs_count} configuraciones, {sessions_count} sesiones, {movements_count} movimientos")

        db.flush()

        # 6. N√ìMINA (v7.7)
        nomina_data = backup_data.get("nomina", {})
        if nomina_data and should_restore('N√≥mina'):
            # 6.1 Configuraci√≥n de N√≥mina
            if "configuraciones" in nomina_data:
                for conf_data in nomina_data["configuraciones"]:
                    # Buscar o crear configuraci√≥n
                    nom_conf = db.query(ConfiguracionNomina).filter(ConfiguracionNomina.empresa_id == target_empresa_id).first()
                    if not nom_conf:
                        nom_conf = ConfiguracionNomina(empresa_id=target_empresa_id)
                        db.add(nom_conf)
                    
                    # Mapear Cuentas y Tipos de Documento
                    if conf_data.get("tipo_documento_codigo"):
                        nom_conf.tipo_documento_id = map_tipos_id.get(conf_data.get("tipo_documento_codigo"))
                    
                    # Mapear cuentas contables
                    for k in ['cuenta_sueldo_codigo', 'cuenta_auxilio_transporte_codigo', 'cuenta_horas_extras_codigo',
                              'cuenta_comisiones_codigo', 'cuenta_otros_devengados_codigo', 'cuenta_salarios_por_pagar_codigo',
                              'cuenta_aporte_salud_codigo', 'cuenta_aporte_pension_codigo', 'cuenta_fondo_solidaridad_codigo',
                              'cuenta_retencion_fuente_codigo', 'cuenta_otras_deducciones_codigo']:
                        if conf_data.get(k):
                            target_k = k.replace('_codigo', '_id')
                            setattr(nom_conf, target_k, map_cuentas.get(conf_data[k]))
                    
                    db.flush()

            # 6.2 Tipos de N√≥mina
            if "tipos" in nomina_data:
                for tipo_data in nomina_data["tipos"]:
                    tipo_nom = db.query(TipoNomina).filter(
                        TipoNomina.empresa_id == target_empresa_id,
                        TipoNomina.nombre == tipo_data["nombre"]
                    ).first()
                    
                    if not tipo_nom:
                        tipo_nom = TipoNomina(
                            empresa_id=target_empresa_id,
                            nombre=tipo_data["nombre"]
                        )
                        db.add(tipo_nom)
                    
                    tipo_nom.descripcion = tipo_data.get("descripcion")
                    tipo_nom.periodo_pago = tipo_data.get("periodo_pago", "Mensual")
                    db.flush()

            # Mapa temporal de Tipos de N√≥mina para referencias
            map_tipos_nomina = _get_id_translation_map(db, TipoNomina, 'nombre', nomina_data, target_empresa_id)

            # 6.3 Empleados
            if "empleados" in nomina_data:
                for emp_data in nomina_data["empleados"]:
                    # Buscar empleado existente por documento
                    empleado = db.query(Empleado).filter(
                        Empleado.empresa_id == target_empresa_id,
                        Empleado.numero_documento == emp_data["numero_documento"]
                    ).first()
                    
                    tipo_nom_id = map_tipos_nomina.get(emp_data.get("tipo_nomina_nombre"))
                    tercero_id = map_terceros.get(emp_data.get("tercero_nit"))
                    
                    if not empleado:
                        empleado = Empleado(
                            empresa_id=target_empresa_id,
                            numero_documento=emp_data["numero_documento"],
                            fecha_ingreso=date.today() # Default preventivo
                        )
                        db.add(empleado)

                    # Actualizar campos b√°sicos
                    for f in ['nombres', 'apellidos', 'email', 'telefono', 'direccion', 'cargo', 
                              'salario_base', 'banco', 'numero_cuenta', 'estado', 'riesgo_arl', 'tipo_contrato']:
                        if f in emp_data: setattr(empleado, f, emp_data[f])
                    
                    empleado.auxilio_transporte = emp_data.get("auxilio_transporte", True)
                    empleado.tipo_nomina_id = tipo_nom_id
                    empleado.tercero_id = tercero_id
                    
                    # Fechas
                    if emp_data.get("fecha_ingreso"):
                        try: empleado.fecha_ingreso = datetime.fromisoformat(emp_data["fecha_ingreso"]).date()
                        except: pass
                    if emp_data.get("fecha_retiro"):
                        try: empleado.fecha_retiro = datetime.fromisoformat(emp_data["fecha_retiro"]).date()
                        except: pass
                    
                    db.flush()

            # Mapa de Empleados
            map_empleados = _get_id_translation_map(db, Empleado, 'numero_documento', nomina_data, target_empresa_id)

            # 6.4 Documentos Hist√≥ricos de N√≥mina
            if "documentos" in nomina_data:
                for nom_data in nomina_data["documentos"]:
                    # Para evitar duplicados hist√≥ricos complejos, verificamos por periodo y tipo
                    # OJO: La clave natural ideal ser√≠a un consecutivo pero n√≥mina no siempre tiene.
                    # Usaremos A√±o + Mes + Quincena
                    
                    nomina_doc = None 
                    # Crear nuevo documento de n√≥mina (asumimos restauraci√≥n hist√≥rica aditiva si no existe exacta)
                    # Simplificaci√≥n: Crear siempre si no hay ID conflicto, pero mejor buscar.
                    
                    # Convertir fechas
                    f_inicio = date.today()
                    f_fin = date.today()
                    try: 
                        f_inicio = datetime.fromisoformat(nom_data["fecha_inicio_periodo"]).date()
                        f_fin = datetime.fromisoformat(nom_data["fecha_fin_periodo"]).date()
                    except: pass

                    nomina_doc = Nomina(
                        empresa_id=target_empresa_id,
                        anio=nom_data["anio"],
                        mes=nom_data["mes"],
                        quincena=nom_data.get("quincena", 0),
                        periodo_pago=nom_data.get("periodo_pago", "Mensual"),
                        fecha_inicio_periodo=f_inicio,
                        fecha_fin_periodo=f_fin,
                        total_devengado=nom_data.get("total_devengado", 0),
                        total_deducciones=nom_data.get("total_deducciones", 0),
                        total_neto=nom_data.get("total_neto", 0),
                        estado='APROBADA',  # Restauramos como hist√≥rica aprobada
                        observaciones=nom_data.get("observaciones")
                    )
                    db.add(nomina_doc)
                    db.flush()

                    # Restaurar Detalles
                    for det_data in nom_data.get("detalles", []):
                         emp_id = map_empleados.get(det_data.get("empleado_documento"))
                         if not emp_id: continue
                         
                         detalle = DetalleNomina(
                             nomina_id=nomina_doc.id,
                             empleado_id=emp_id,
                             dias_trabajados=det_data.get("dias_trabajados", 30),
                             total_devengado=det_data.get("total_devengado", 0),
                             total_deducciones=det_data.get("total_deducciones", 0),
                             neto_pagar=det_data.get("neto_pagar", 0)
                             # ... se podr√≠an mapear todos los campos num√©ricos ...
                         )
                         
                         # Mapear campos detallados
                         for f in ['sueldo_basico_periodo', 'auxilio_transporte_periodo', 'horas_extras_total', 
                                   'recargos_total', 'comisiones', 'otros_devengados', 
                                   'salud_empleado', 'pension_empleado', 'fondo_solidaridad', 'retencion_fuente',
                                   'prestamos', 'otras_deducciones']:
                             if f in det_data: setattr(detalle, f, det_data[f])

                         db.add(detalle)

            resumen["acciones_realizadas"].append(f"üë∑ N√≥mina restaurada: {len(nomina_data.get('empleados', []))} empleados procesados.")
        
        db.flush()

        # 7. TRANSACCIONES
        docs_source = backup_data.get("transacciones") or backup_data.get("documentos") or []
        if docs_source and should_restore('Documentos y Movimientos'):
            map_tipos_final = _get_id_translation_map(db, TipoDocumento, 'codigo', maestros_src, target_empresa_id)
            tipos_db = db.query(TipoDocumento).filter(TipoDocumento.empresa_id == target_empresa_id).all()
            for t in tipos_db: map_tipos_final[t.codigo] = t.id

            existing_docs = db.query(Documento).filter(Documento.empresa_id == target_empresa_id).all()
            map_existing_key_to_obj = {f"{d.tipo_documento_id}-{d.numero}": d for d in existing_docs}
            
            deleted_docs = db.query(DocumentoEliminado).filter(DocumentoEliminado.empresa_id == target_empresa_id).all()
            map_deleted = {f"{d.tipo_documento_id}-{str(d.numero)}": d for d in deleted_docs}

            ids_vivos_en_backup = set()
            creados_count = 0
            actualizados_count = 0
            exorcizados_count = 0
            terceros_afectados = set()

            for doc_data in docs_source:
                tipo_codigo = doc_data.get('tipo_doc_codigo')
                tipo_id = map_tipos_final.get(tipo_codigo)
                if not tipo_id: continue
                
                natural_key = f"{tipo_id}-{str(doc_data['numero'])}"
                
                fantasma = map_deleted.get(natural_key)
                if fantasma:
                    db.delete(fantasma)
                    exorcizados_count += 1

                documento_bd = map_existing_key_to_obj.get(natural_key)
                tercero_id = map_terceros.get(doc_data.get('tercero_nit'))
                if tercero_id: terceros_afectados.add(tercero_id)
                cc_id = map_ccs.get(doc_data.get('centro_costo_codigo'))

                val_anulado = doc_data.get('anulado', False)
                val_estado = 'ANULADO' if val_anulado else 'ACTIVO'
                
                fecha_doc = None
                if doc_data.get('fecha'):
                    try:
                        fecha_doc = datetime.fromisoformat(doc_data['fecha'])
                    except:
                        fecha_doc = datetime.utcnow()
                else:
                    fecha_doc = datetime.utcnow()

                if documento_bd:
                    documento_bd.fecha = fecha_doc
                    documento_bd.beneficiario_id = tercero_id
                    documento_bd.observaciones = doc_data.get('observaciones')
                    documento_bd.anulado = val_anulado
                    documento_bd.estado = val_estado
                    
                    db.query(MovimientoContable).filter(MovimientoContable.documento_id == documento_bd.id).delete()
                    db.query(MovimientoInventario).filter(MovimientoInventario.documento_id == documento_bd.id).delete()
                    actualizados_count += 1
                    ids_vivos_en_backup.add(documento_bd.id)
                else:
                    documento_bd = Documento(
                        empresa_id=target_empresa_id, tipo_documento_id=tipo_id, numero=doc_data['numero'],
                        fecha=fecha_doc, beneficiario_id=tercero_id, centro_costo_id=cc_id,
                        anulado=val_anulado, estado=val_estado,
                        usuario_creador_id=user_id, fecha_operacion=datetime.utcnow()
                    )
                    db.add(documento_bd)
                    db.flush()
                    creados_count += 1
                    ids_vivos_en_backup.add(documento_bd.id)

                for mov in doc_data.get('movimientos_contables', []):
                    cta_id = map_cuentas.get(mov['cuenta_codigo'])
                    prod_id = None
                    if mov.get('producto_codigo'):
                        prod_id = map_productos.get(mov['producto_codigo'])

                    if cta_id:
                        db.add(MovimientoContable(
                            documento_id=documento_bd.id, 
                            cuenta_id=cta_id, 
                            concepto=mov['concepto'], 
                            debito=mov['debito'], 
                            credito=mov['credito'],
                            producto_id=prod_id,
                            cantidad=mov.get('cantidad', 0)
                        ))
                
                for mov_inv in doc_data.get('movimientos_inventario', []):
                    prod_id = map_productos.get(mov_inv['producto_codigo'])
                    bod_id = map_bodegas.get(mov_inv['bodega_nombre'])
                    if prod_id and bod_id:
                        db.add(MovimientoInventario(
                            documento_id=documento_bd.id, producto_id=prod_id, bodega_id=bod_id, 
                            tipo_movimiento=mov_inv['tipo'], cantidad=mov_inv['cantidad'], 
                            costo_unitario=mov_inv['costo_unitario'], costo_total=mov_inv['costo_total'], 
                            fecha=fecha_doc
                        ))
            
            if exorcizados_count > 0:
                resumen["acciones_realizadas"].append(f"üëª EXORCISMO: {exorcizados_count} documentos recuperados.")

            # --- CORRECCI√ìN v7.0: Se elimin√≥ el bloque de BORRADO de documentos sobrantes ---
            # Esto evita que se borre el historial existente al importar copias parciales.

            resumen["acciones_realizadas"].append(f"üì• {creados_count} Documentos Creados")
            resumen["acciones_realizadas"].append(f"‚úèÔ∏è {actualizados_count} Documentos Corregidos")

            _reconstruir_saldos_inventario(db, target_empresa_id)
            resumen["acciones_realizadas"].append("üì¶ Stocks y COSTOS de inventario reconstruidos.")

            if terceros_afectados:
                for tid in terceros_afectados:
                    try:
                        services_cartera.recalcular_aplicaciones_tercero(db, tercero_id=tid, empresa_id=target_empresa_id)
                    except:
                        pass # Tolerancia a errores de rec√°lculo
                resumen["acciones_realizadas"].append(f"üí∞ Saldos de cartera recalculados para {len(terceros_afectados)} terceros.")

        # --- ATOMICIDAD: EL √öNICO COMMIT DE TODA LA OPERACI√ìN ---
        db.commit()
        
        # Verificar integridad referencial despu√©s del commit
        integridad = verificar_integridad_referencial(db, target_empresa_id)
        if not integridad['integridad_valida']:
            resumen["acciones_realizadas"].append(f"‚ö†Ô∏è Advertencias de integridad: {'; '.join(integridad['errores'])}")
        else:
            resumen["acciones_realizadas"].append("‚úÖ Verificaci√≥n de integridad referencial: OK")
        
        return {"message": "Restauraci√≥n Protocolo Fusi√≥n v7.6 Finalizada - Nuevos m√≥dulos incluidos (Datos existentes preservados)", "resumen": resumen}

    except Exception as e:
        # --- ROLLBACK TOTAL ---
        print(f"‚ùå [ERROR] Error cr√≠tico durante restauraci√≥n para empresa {target_empresa_id}: {str(e)}")
        print(f"üìä [ROLLBACK] Revirtiendo todos los cambios...")
        
        db.rollback()
        
        # Verificar que el rollback fue exitoso
        try:
            # Intentar una consulta simple para verificar que la conexi√≥n sigue funcionando
            db.execute(select(func.count()).select_from(Empresa).where(Empresa.id == target_empresa_id))
            print(f"‚úÖ [ROLLBACK] Rollback completado exitosamente")
        except Exception as rollback_error:
            print(f"‚ö†Ô∏è [ROLLBACK] Error durante verificaci√≥n post-rollback: {str(rollback_error)}")
        
        traceback.print_exc()
        
        # Agregar informaci√≥n del contexto al error
        error_context = {
            "empresa_id": target_empresa_id,
            "user_id": user_id,
            "backup_version": backup_data.get("metadata", {}).get("version_sistema", "unknown"),
            "backup_source": backup_data.get("metadata", {}).get("empresa_id_origen", "unknown")
        }
        
        raise HTTPException(
            status_code=500, 
            detail=f"Error fatal durante restauraci√≥n (Operaci√≥n Revertida Completamente): {str(e)}. Contexto: {error_context}"
        )

# =====================================================================================
# AUXILIARES
# =====================================================================================
def _reconstruir_saldos_inventario(db: Session, empresa_id: int):
    productos = db.query(Producto.id).filter(Producto.empresa_id == empresa_id).all()
    prod_ids = [p.id for p in productos]
    if not prod_ids: return

    db.query(StockBodega).filter(StockBodega.producto_id.in_(prod_ids)).delete(synchronize_session=False)
    
    stmt = (
        select(
            MovimientoInventario.producto_id,
            MovimientoInventario.bodega_id,
            func.sum(
                case(
                    (MovimientoInventario.tipo_movimiento.like('SALIDA%'), -MovimientoInventario.cantidad),
                    else_=MovimientoInventario.cantidad
                )
            ).label('nuevo_stock'),
            func.sum(
                case(
                    (MovimientoInventario.tipo_movimiento.like('SALIDA%'), -MovimientoInventario.costo_total),
                    else_=MovimientoInventario.costo_total
                )
            ).label('nuevo_valor_total')
        )
        .join(Producto, MovimientoInventario.producto_id == Producto.id)
        .filter(Producto.empresa_id == empresa_id)
        .group_by(MovimientoInventario.producto_id, MovimientoInventario.bodega_id)
    )
    resultados = db.execute(stmt).all()
    
    nuevos_stocks = []
    global_prod_stats = {} 

    for row in resultados:
        if row.nuevo_stock != 0:
            nuevos_stocks.append(StockBodega(producto_id=row.producto_id, bodega_id=row.bodega_id, stock_actual=row.nuevo_stock))
        
        if row.producto_id not in global_prod_stats:
            global_prod_stats[row.producto_id] = {"qty": 0, "val": 0}
        
        global_prod_stats[row.producto_id]["qty"] += row.nuevo_stock
        global_prod_stats[row.producto_id]["val"] += (row.nuevo_valor_total or 0)

    if nuevos_stocks:
        db.bulk_save_objects(nuevos_stocks)
    
    for pid, stats in global_prod_stats.items():
        qty = stats["qty"]
        val = stats["val"]
        costo_promedio = 0
        if qty > 0:
            costo_promedio = val / qty
        db.query(Producto).filter(Producto.id == pid).update({"costo_promedio": costo_promedio})

def _get_id_translation_map(db, model, natural_key, data_source, target_empresa_id):
    """Crea un mapa de traducci√≥n de IDs entre backup y base de datos destino."""
    target_rows = db.query(model.id, getattr(model, natural_key)).filter(model.empresa_id == target_empresa_id).all()
    target_map = {str(getattr(r, natural_key)).strip(): r.id for r in target_rows}
    id_map = target_map.copy() 
    
    # Mapeo mejorado de nombres de tablas a claves JSON
    table_to_json_key = {
        'grupos_inventario': 'grupos',
        'plan_cuentas': 'plan_cuentas',
        'centros_costo': 'centros_costo',
        'tipos_documento': 'tipos_documento',
        'cotizaciones': 'cotizaciones',
        'recetas': 'recetas',
        'ordenes_produccion': 'ordenes',
        'import_configs': 'configuraciones_importacion',
        'import_sessions': 'sesiones_importacion',
        'bank_movements': 'movimientos_bancarios'
    }
    
    json_key = table_to_json_key.get(model.__tablename__, model.__tablename__)
    
    # Buscar en diferentes secciones del backup
    source_rows = []
    if json_key in data_source:
        source_rows = data_source[json_key]
    else:
        # Buscar en subsecciones para m√≥dulos especializados
        for section in ['cotizaciones', 'produccion', 'conciliacion_bancaria']:
            if section in data_source and json_key in data_source[section]:
                source_rows = data_source[section][json_key]
                break
    
    # Crear mapeos bidireccionales para mayor robustez
    for row in source_rows:
        if not isinstance(row, dict):
            continue
            
        key_val = str(row.get(natural_key, '')).strip()
        if key_val and key_val in target_map:
            nuevo_id = target_map[key_val]
            
            # Mapear ID original si existe
            old_id = row.get('id')
            if old_id: 
                id_map[str(old_id)] = nuevo_id
            
            # Mapear c√≥digo si existe y es diferente de natural_key
            codigo = row.get('codigo')
            if codigo and codigo != key_val:
                id_map[str(codigo)] = nuevo_id
                
            # Mapear clave natural
            id_map[str(key_val)] = nuevo_id
            
            # Mapear ID de origen si existe (para compatibilidad)
            if 'id_origen' in row:
                id_map[str(row['id_origen'])] = nuevo_id
                
    return id_map

def verificar_integridad_referencial(db: Session, empresa_id: int) -> dict:
    """Verifica la integridad referencial despu√©s de una restauraci√≥n."""
    errores = []
    
    try:
        # Verificar cotizaciones
        cotizaciones_huerfanas = db.query(Cotizacion).filter(
            Cotizacion.empresa_id == empresa_id,
            Cotizacion.tercero_id.isnot(None)
        ).outerjoin(Tercero, Cotizacion.tercero_id == Tercero.id).filter(
            Tercero.id.is_(None)
        ).count()
        
        if cotizaciones_huerfanas > 0:
            errores.append(f"Cotizaciones con terceros inexistentes: {cotizaciones_huerfanas}")
        
        # Verificar recetas
        recetas_huerfanas = db.query(Receta).filter(
            Receta.empresa_id == empresa_id
        ).outerjoin(Producto, Receta.producto_id == Producto.id).filter(
            Producto.id.is_(None)
        ).count()
        
        if recetas_huerfanas > 0:
            errores.append(f"Recetas con productos inexistentes: {recetas_huerfanas}")
        
        # Verificar configuraciones bancarias
        configs_huerfanas = db.query(AccountingConfig).filter(
            AccountingConfig.empresa_id == empresa_id
        ).outerjoin(PlanCuenta, AccountingConfig.bank_account_id == PlanCuenta.id).filter(
            PlanCuenta.id.is_(None)
        ).count()
        
        if configs_huerfanas > 0:
            errores.append(f"Configuraciones bancarias con cuentas inexistentes: {configs_huerfanas}")
            
    except Exception as e:
        errores.append(f"Error durante verificaci√≥n: {str(e)}")
    
    return {
        'integridad_valida': len(errores) == 0,
        'errores': errores
    }

def verificar_compatibilidad_version(version_backup: str) -> dict:
    """Verifica la compatibilidad de una versi√≥n de backup con el sistema actual."""
    version_actual = "7.7"
    
    # Parsear versiones
    try:
        version_backup_parts = [int(x) for x in version_backup.split('.')]
        version_actual_parts = [int(x) for x in version_actual.split('.')]
    except:
        return {
            'compatible': False,
            'requiere_migracion': False,
            'mensaje': f"Versi√≥n de backup inv√°lida: {version_backup}"
        }
    
    # Verificar compatibilidad
    if version_backup_parts[0] < 7:
        return {
            'compatible': False,
            'requiere_migracion': True,
            'mensaje': f"Backup v{version_backup} requiere migraci√≥n manual. Contacte soporte t√©cnico."
        }
    elif version_backup_parts == version_actual_parts:
        return {
            'compatible': True,
            'requiere_migracion': False,
            'mensaje': f"Backup v{version_backup} es totalmente compatible"
        }
    elif version_backup_parts[0] == version_actual_parts[0] and version_backup_parts[1] <= version_actual_parts[1]:
        return {
            'compatible': True,
            'requiere_migracion': False,
            'mensaje': f"Backup v{version_backup} es compatible con v{version_actual} (compatibilidad hacia atr√°s)"
        }
    else:
        return {
            'compatible': False,
            'requiere_migracion': False,
            'mensaje': f"Backup v{version_backup} es m√°s nuevo que el sistema v{version_actual}. Actualice el sistema."
        }

def migrar_backup_version(backup_data: dict, version_origen: str, version_destino: str) -> dict:
    """Migra un backup de una versi√≥n anterior al formato actual."""
    print(f"üîÑ [MIGRATION] Migrando backup de v{version_origen} a v{version_destino}")
    
    # Migraci√≥n de v7.0-7.6 a v7.7
    if version_origen.startswith("7.") and version_destino == "7.7":
        # Agregar secciones faltantes si no existen
        if "cotizaciones" not in backup_data:
            backup_data["cotizaciones"] = {}
        if "produccion" not in backup_data:
            backup_data["produccion"] = {}
        if "conciliacion_bancaria" not in backup_data:
            backup_data["conciliacion_bancaria"] = {}
        
        # Actualizar metadata
        if "metadata" in backup_data:
            backup_data["metadata"]["version_sistema"] = version_destino
            backup_data["metadata"]["migrado_desde"] = version_origen
        
        print(f"‚úÖ [MIGRATION] Migraci√≥n completada de v{version_origen} a v{version_destino}")
    
    return backup_data

def _restore_jerarquico(db, model, json_key, parent_field, data_source, target_empresa_id, user_id):
    rows = data_source.get(json_key, [])
    if not rows: return 0
    
    existing = db.query(model).filter(model.empresa_id == target_empresa_id).all()
    exist_map = {str(r.codigo).strip(): r for r in existing}
    
    by_level = {}
    for r in rows:
        lvl = r.get('nivel', 1)
        if lvl not in by_level: by_level[lvl] = []
        by_level[lvl].append(r)
    
    count = 0
    for lvl in sorted(by_level.keys()):
        for item in by_level[lvl]:
            key = str(item.get('codigo')).strip()
            if key not in exist_map:
                new_item = item.copy()
                # CORRECCI√ìN COMBINADA: Limpiar campos de auditor√≠a antiguos (Antigravity + Kiro)
                for k in ['id', '_sa_instance_state', 'created_at', 'updated_at']: new_item.pop(k, None)
                
                # ARREGLO KIRO: Validar y corregir foreign keys de usuarios antes de procesar
                for user_field in ['created_by', 'updated_by', 'usuario_creador_id', 'usuario_modificador_id']:
                    if user_field in new_item and new_item[user_field] is not None:
                        # Verificar si el usuario existe, si no, usar el usuario actual
                        user_exists = db.query(Usuario).filter(Usuario.id == new_item[user_field]).first()
                        if not user_exists:
                            new_item[user_field] = user_id
                
                new_item['empresa_id'] = target_empresa_id
                new_item[parent_field] = None 
                
                # ARREGLO COMBINADO: Manejar todos los campos de foreign key a usuarios
                if hasattr(model, 'created_by'): new_item['created_by'] = user_id
                if hasattr(model, 'updated_by'): new_item['updated_by'] = user_id
                obj = model(**new_item)
                db.add(obj)
                exist_map[key] = obj
                count += 1
            else:
                # UPDATE LOGIC: If account exists, check if name needs update (e.g. sanitization fix)
                existing_obj = exist_map[key]
                new_name = item.get('nombre')
                if new_name and existing_obj.nombre != new_name:
                    existing_obj.nombre = new_name
                
                # ARREGLO COMBINADO: Validar campos de usuario en actualizaciones (Kiro + Antigravity)
                for user_field in ['updated_by']:
                    if user_field in item and item[user_field] is not None:
                        user_exists = db.query(Usuario).filter(Usuario.id == item[user_field]).first()
                        if not user_exists:
                            setattr(existing_obj, user_field, user_id)
                        else:
                            setattr(existing_obj, user_field, item[user_field])
                    elif hasattr(model, user_field):
                        # Si no hay valor en item, usar user_id actual (mejora de Antigravity)
                        setattr(existing_obj, user_field, user_id)

    # --- FASE 2: RECONSTRUCCI√ìN INTELIGENTE DE JERARQU√çA (Antigravity Fix) ---
    # Una vez que todas las cuentas existen, reconectamos padres e hijos bas√°ndonos en C√ìDIGOS, no en IDs.
    
    # Mapa actualizado de todo lo que existe (incluyendo lo reci√©n creado)
    db.flush()
    existing_final = db.query(model).filter(model.empresa_id == target_empresa_id).all()
    map_codigo_obj = {str(r.codigo).strip(): r for r in existing_final}
    
    # 1. Auto-Creaci√≥n de Padres Faltantes (Gaps/Huecos)
    # Analizamos todos los c√≥digos para ver si falta alg√∫n padre intermedio
    nuevos_padres_creados = 0
    nuevos_padres_pendientes = {} # Codigo -> Nivel
    
    codigos_actuales = set(map_codigo_obj.keys())
    
    for codigo in codigos_actuales:
        ancestros = []
        # Descomposici√≥n jer√°rquica standard (1, 2, 4, 6, 8...)
        if len(codigo) > 1: ancestros.append(codigo[:1]) # Clase
        if len(codigo) > 2: ancestros.append(codigo[:2]) # Grupo
        if len(codigo) > 4: ancestros.append(codigo[:4]) # Cuenta
        if len(codigo) > 6: ancestros.append(codigo[:-2]) # Subcuenta gen√©rica
        
        for ancestro in ancestros:
            if ancestro not in codigos_actuales and ancestro not in nuevos_padres_pendientes:
                # Determinar nivel l√≥gico para el padre faltante
                lvl = 1
                if len(ancestro) == 2: lvl = 2
                elif len(ancestro) == 4: lvl = 3
                elif len(ancestro) == 6: lvl = 4
                elif len(ancestro) >= 8: lvl = 5
                
                nuevos_padres_pendientes[ancestro] = lvl
    
    # Crear los padres faltantes
    if nuevos_padres_pendientes:
        print(f"üîß [RESTORE] Auto-creando {len(nuevos_padres_pendientes)} cuentas padre faltantes para integridad estructural.")
        for nuevo_codigo, nivel in sorted(nuevos_padres_pendientes.items(), key=lambda x: len(x[0])):
            nueva_cuenta = model(
                empresa_id=target_empresa_id,
                codigo=nuevo_codigo,
                nombre=f"CUENTA GENERADA {nuevo_codigo}",
                nivel=nivel,
                created_by=user_id,
                updated_by=user_id
                # El padre se asignar√° en el paso de relink general
            )
            # Manejar campos espec√≠ficos si es PlanCuenta
            # Usamos getattr/setattr para ser gen√©ricos (aunque esto solo aplica a modelos que suporten hierarchy)
            if hasattr(model, 'permite_movimiento'): 
                 if hasattr(nueva_cuenta, 'permite_movimiento'): nueva_cuenta.permite_movimiento = False
            
            db.add(nueva_cuenta)
            db.flush() # Necesario generar ID
            map_codigo_obj[nuevo_codigo] = nueva_cuenta
            nuevos_padres_creados += 1

    # 2. Relink General (Asignar Padres) y 3. Rec√°lculo de Niveles
    # Iteramos sobre TODO el universo de cuentas de la empresa para asegurar consistencia total
    updates_relink = 0
    updates_level = 0
    
    for codigo, obj in map_codigo_obj.items():
        dirty = False
        
        # A. CALCULAR NIVEL CORRECTO
        longitud = len(codigo)
        nivel_calc = 1
        if longitud == 1: nivel_calc = 1
        elif longitud == 2: nivel_calc = 2
        elif longitud == 4: nivel_calc = 3
        elif longitud == 6: nivel_calc = 4
        elif longitud == 8: nivel_calc = 5
        elif longitud > 8: nivel_calc = 5 + ((longitud - 8) // 2)
        
        # Verificar atributo nivel existe
        if hasattr(obj, 'nivel'):
            if obj.nivel != nivel_calc:
                obj.nivel = nivel_calc
                dirty = True
                updates_level += 1
            
        # B. ASIGNAR PADRE (B√∫squeda por c√≥digo)
        if hasattr(obj, parent_field):
            if longitud > 1:
                padre_cod = None
                if longitud == 2: padre_cod = codigo[:1]
                elif longitud == 4: padre_cod = codigo[:2]
                elif longitud == 6: padre_cod = codigo[:4]
                elif longitud >= 8: padre_cod = codigo[:-2]
                
                if padre_cod and padre_cod in map_codigo_obj:
                    padre_obj = map_codigo_obj[padre_cod]
                    if getattr(obj, parent_field) != padre_obj.id:
                        setattr(obj, parent_field, padre_obj.id)
                        dirty = True
                        updates_relink += 1
                else:
                    # Si no tiene padre (por ser ra√≠z o error raro), asegurar None
                    if getattr(obj, parent_field) is not None:
                        setattr(obj, parent_field, None)
                        dirty = True
            else:
                # Nivel 1 siempre hu√©rfano
                if getattr(obj, parent_field) is not None:
                    setattr(obj, parent_field, None)
                    dirty = True

    if updates_relink > 0 or updates_level > 0:
         print(f"‚úÖ [RESTORE] Jerarqu√≠a reparada: {updates_relink} enlaces padre-hijo, {updates_level} correcciones de nivel.")

    return count

def _upsert_manual_seguro(db, model, json_key, natural_key, data_source, target_empresa_id, user_id, id_maps=None):
    rows = data_source.get(json_key, [])
    if not rows: return 0

    existing_records = db.query(model).filter(model.empresa_id == target_empresa_id).all()
    existing_map = {str(getattr(r, natural_key)).strip(): r for r in existing_records}

    valid_columns = {c.name for c in model.__table__.columns}
    immutable_cols = {'id', 'empresa_id', 'created_at', 'fecha_creacion', 'created_by', 'usuario_creador_id'}
    if natural_key: immutable_cols.add(natural_key)

    count = 0
    for r in rows:
        data = r.copy()
        # CORRECCI√ìN: Eliminar updated_by del diccionario origen para evitar FK Error
        for k in ['id', '_sa_instance_state', 'created_at', 'updated_at', 'fecha_creacion', 'updated_by']: data.pop(k, None)
        
        clean_data = {k: v for k, v in data.items() if k in valid_columns}
        
        # ARREGLO: Validar y corregir foreign keys de usuarios antes de procesar
        for user_field in ['created_by', 'updated_by', 'usuario_creador_id', 'usuario_modificador_id']:
            if user_field in clean_data and clean_data[user_field] is not None:
                # Verificar si el usuario existe, si no, usar el usuario actual
                user_exists = db.query(Usuario).filter(Usuario.id == clean_data[user_field]).first()
                if not user_exists:
                    clean_data[user_field] = user_id
        
        if id_maps:
            for field, mapping in id_maps.items():
                old_val = clean_data.get(field)
                mapped_id = None
                
                # 1. Try mapping the primary field (usually an ID)
                if old_val is not None:
                    mapped_id = mapping.get(str(old_val).strip())
                
                # 2. If valid mapping not found, try fallback fields (Code or Name)
                if mapped_id is None:
                    code_field = field.replace('_id', '_codigo')
                    alt_val = r.get(code_field)
                    if alt_val is not None:
                        mapped_id = mapping.get(str(alt_val).strip())
                
                if mapped_id is None:
                     name_field = field.replace('_id', '_nombre')
                     alt_val = r.get(name_field)
                     if alt_val is not None:
                         mapped_id = mapping.get(str(alt_val).strip())

                if mapped_id:
                    clean_data[field] = mapped_id
                else:
                    # If strictly required foreign key and we failed to map, explicitly set None 
                    # (This will cause IntegrityError, but better than silent wrong ID)
                    clean_data[field] = None

        key_val = str(clean_data.get(natural_key)).strip()
        
        if key_val in existing_map:
            obj = existing_map[key_val]
            for k, v in clean_data.items():
                if k not in immutable_cols:
                    setattr(obj, k, v)
            if hasattr(model, 'updated_by'): obj.updated_by = user_id
        else:
            clean_data['empresa_id'] = target_empresa_id
            # ARREGLO: Manejar todos los campos de foreign key a usuarios
            if hasattr(model, 'created_by'): clean_data['created_by'] = user_id
            if hasattr(model, 'updated_by'): clean_data['updated_by'] = user_id
            new_obj = model(**clean_data)
            db.add(new_obj)
            existing_map[key_val] = new_obj
            
        count += 1
    return count

def exportar_datos(db: Session, export_request: schemas_migracion.ExportRequest, empresa_id: int):
    # CORRECCI√ìN v6.6: Usamos exclude_none en lugar de exclude_unset y convertimos
    # para asegurar que el diccionario tenga todas las llaves posibles
    filtros = export_request.dict(exclude_none=True)
    return generar_backup_json(db, empresa_id, filtros)

def obtener_modulos_disponibles(db: Session, empresa_id: int):
    """
    Obtiene informaci√≥n sobre m√≥dulos disponibles y sus dependencias.
    
    Esta funci√≥n utiliza el sistema declarativo de m√≥dulos para:
    - Validar dependencias de cada m√≥dulo
    - Contar registros existentes
    - Determinar disponibilidad para exportaci√≥n
    
    Returns:
        dict: Informaci√≥n detallada de cada m√≥dulo configurado
    """
    modulos_info = {}
    
    for modulo_name, config in MODULOS_ESPECIALIZADOS_CONFIG.items():
        validacion = validar_dependencias_modulo(db, config, empresa_id)
        
        # Contar registros existentes
        count_principales = 0
        for modelo in config.get('modelos_principales', []):
            if hasattr(modelo, 'empresa_id'):
                count_principales += db.query(func.count(modelo.id)).filter(modelo.empresa_id == empresa_id).scalar()
        
        modulos_info[modulo_name] = {
            'descripcion': config['descripcion'],
            'dependencias_validas': validacion['valido'],
            'dependencias_faltantes': validacion['dependencias_faltantes'],
            'registros_existentes': count_principales,
            'disponible': validacion['valido']
        }
    
    return modulos_info

# =====================================================================================
# RESUMEN DE ACTUALIZACI√ìN v7.6
# =====================================================================================
"""
ACTUALIZACI√ìN DEL SISTEMA DE MIGRACI√ìN DE DATOS v7.6

Nuevos m√≥dulos agregados:
‚úÖ Cotizaciones - Cotizaciones maestras y detalles con relaciones completas
‚úÖ Producci√≥n - Recetas, √≥rdenes, recursos e insumos con configuraci√≥n
‚úÖ Conciliaci√≥n Bancaria - Configuraciones, sesiones y movimientos bancarios

Mejoras implementadas:
‚úÖ Sistema declarativo de registro de m√≥dulos
‚úÖ Validaci√≥n autom√°tica de dependencias
‚úÖ Verificaci√≥n de integridad referencial post-restauraci√≥n
‚úÖ Compatibilidad hacia atr√°s con versiones anteriores
‚úÖ Migraci√≥n autom√°tica de formatos de backup
‚úÖ Logging mejorado y mensajes de feedback detallados
‚úÖ Interfaz de usuario actualizada con descripciones claras

Caracter√≠sticas t√©cnicas:
- Mantiene atomicidad total en restauraci√≥n
- Preserva datos existentes (modo fusi√≥n segura)
- Firma digital para validaci√≥n de integridad
- Mapeo robusto de IDs entre empresas
- Manejo de errores con rollback autom√°tico

Para usar los nuevos m√≥dulos:
1. Seleccionar en la interfaz de exportaci√≥n
2. El sistema validar√° dependencias autom√°ticamente
3. La restauraci√≥n manejar√° las relaciones correctamente
4. Verificaci√≥n de integridad al finalizar
"""